{{autogenerated}}

import os
import logging
import threading
import time
from tempfile import NamedTemporaryFile
from typing import List, Tuple, Any
from fastapi import APIRouter, Depends, File, HTTPException, Response, UploadFile, Query
from fastapi.security.api_key import APIKey
from fastapi.encoders import jsonable_encoder
from fastapi.responses import JSONResponse
from starlette.status import (
    HTTP_200_OK,
    HTTP_400_BAD_REQUEST,
    HTTP_403_FORBIDDEN,
    HTTP_500_INTERNAL_SERVER_ERROR,
)

from ssf.common_runtime.common import *
from server import applications
from server_security import router
from server_security import get_api_key
from pydantic import BaseModel

logger = logging.getLogger('ssf')
id = "{{config.application.id}}"
logger.info(f"Loaded {__file__} for {id} endpoint")

router = APIRouter(tags=["{{config.application.name}}"])

class Inputs(BaseModel):
    {{inputs_as_base_model}}
    pass

@router.post(
    "/v{{endpoint.version}}/{{endpoint.id}}",
    include_in_schema=True,
    responses={
        HTTP_200_OK: {
            "description": "Successful request",
        },
        HTTP_400_BAD_REQUEST: {
            "model": HTTPError,
            "description": "HTTPException thrown due to a bad request inputs.",
        },
        HTTP_403_FORBIDDEN: {
            "model": HTTPError,
            "description": "HTTPException thrown due to invalid credentials.",
        },
        HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": HTTPError,
            "description": "HTTPException thrown due to a failure while processing the request.",
        },
    },
    response_class=Response,
)
def run_{{endpoint.id}}_v{{endpoint.version}} (
    {{inputs_as_params}},
    api_key: APIKey = Depends(get_api_key),
):
    """
    {{endpoint.description}}

    Arguments:

    {{inputs_as_doc_strings}}

    Returns:

    {{outputs_as_doc_strings}}

    In addition, the response headers will include the following metadata:
    - metrics-dispatch-latency : time in dispatcher to process the request.
    """

    if {{config.application.trace:False}}:
        logger.info(f"> {{config.application.name}} Enter")

    request_queued_time = time.time()

    try:
        {{preprocess}}

        request_params_dict = {
            {{request_params_fields}}
        }

        request_meta_dict = {
            {{request_meta_fields}}
        }

        if {{config.application.trace:False}}:
            logger.info(f"> {{config.application.name}} request_params_dict.keys={request_params_dict.keys()}")
            logger.info(f"> {{config.application.name}} request_meta_dict.keys={request_meta_dict.keys()}")
            logger.debug(f"> {{config.application.name}} queue request request_params_dict={request_params_dict}")
            logger.debug(f"> {{config.application.name}} queue request request_meta_dict={request_meta_dict}")

        applications.dispatcher["{{config.application.id}}"].queue_request((request_params_dict, request_meta_dict))
        results = applications.dispatcher["{{config.application.id}}"].get_result()

        result_dequeued_time = time.time()
        dispatch_latency = str(results[HEADER_METRICS_DISPATCH_LATENCY])

        if {{config.application.trace:False}}:
            logger.info(f"> {{config.application.name}} results {results.keys()}")
            logger.debug(f"> {{config.application.name}} results {results}")

        headers = {
            HEADER_METRICS_DISPATCH_LATENCY: str(dispatch_latency),
        }

        {{postprocess}}

        if {{config.application.trace:False}}:
            logger.info(f"> {{config.application.name}} Leave ({dispatch_latency})")


        {{returns}}

    except HTTPException:
        if {{config.application.trace:False}}:
            logger.exception(f"Processing endpoint")
        raise
    except Exception:
        if {{config.application.trace:False}}:
            logger.exception(f"Processing endpoint")
        raise HTTPException(
            HTTP_400_BAD_REQUEST, detail="There was an error processing inputs"
        )
