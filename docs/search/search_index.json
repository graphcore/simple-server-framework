{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is SSF?","text":""},{"location":"#simple-server-framework","title":"Simple Server Framework","text":""},{"location":"#documentation","title":"Documentation:","text":"<p>\ud83d\udcd6 SSF user guide</p>"},{"location":"#overview","title":"Overview","text":"<p>Graphcore's Simple Server Framework (SSF) is a tool for building, running and packaging (containerising) applications for serving. It can be used to serve any machine learning inference models running on IPUs and automate their deployment on supported cloud platforms.</p> <p>Using SSF simplifies deployment and reduces code repetition and redundancy when working with several independent applications.</p> <p>SSF has the following features:</p> <ul> <li>Minimal code required for applications</li> <li>Declarative configuration that is serving framework agnostic</li> <li>No specific machine learning model formats required</li> <li>Standardised application interface</li> <li>Serving framework implementation details are retained by SSF</li> </ul>"},{"location":"#basics","title":"Basics","text":"<p>Each application requires two things:</p> <ul> <li>An application interface (Python module to receive 'build' and 'run' requests)</li> <li>A declarative configuration that provides some details, including a definition of request inputs and outputs.</li> </ul> <p>Once the application interface and configuration have been set up then SSF can be used with the following commands (note that these commands can be issued individually or combined):</p> <ul> <li><code>init</code></li> <li><code>build</code></li> <li><code>run</code></li> <li><code>package</code></li> <li><code>publish</code></li> <li><code>deploy</code></li> </ul> <p>As an example, if you run:</p> <p><pre><code>gc-ssf --config examples/simple/ssf_config.yaml init build package\n</code></pre> you will create a clean packaged application with served endpoints. To take another example, if you run:</p> <p><pre><code>gc-ssf --config examples/simple/ssf_config.yaml build run\n</code></pre> you will build and run the application with served endpoints from source.</p>"},{"location":"advanced/","title":"Advanced","text":""},{"location":"advanced/#advanced","title":"Advanced","text":""},{"location":"advanced/#create-a-test-interface-for-your-application","title":"Create a test interface for your application","text":"<p>You can define a series of tests for your application. Such tests will be run when issuing the command <code>test</code>. The logic is similar to the application interface - you need to define a test client. This is a handler for a Python requests <code>session</code>. When running <code>gc-ssf test</code> an instance of your server will run and a test client will issue the standard SSF tests as well as your custom tests.</p> <p>For example:</p> <p>In the same Python file where you defined the <code>SSFApplicationInterface</code>, define a child class of <code>SSFApplicationTestInterface</code> and implement the required methods:</p> <pre><code>from ssf.application import SSFApplicationTestInterface\nlogger = logging.getLogger()\nclass MyTestClient(SSFApplicationTestInterface):\ndef begin(self, session, ipaddr: str) -&gt; int:\n\"\"\"\n            Begin application testing.\n                    session: The Python requests library session (credentials are initialised before calling into application tests).\n                    ipaddr (str): IP address including port (e.g. \"http://0.0.0.0:8100\")\n            Returns:\n                    0 if successful.\n            \"\"\"\nlogger.info(\"MyApp test begin\")\nreturn 0\ndef subtest(self, session, ipaddr: str, index: int) -&gt; Tuple[bool, str, bool]:\n\"\"\"\n            Issue test.\n            Parameters:\n                    session: The Python requests library session (credentials are initialised before calling into application tests).\n                    ipaddr (str): IP address including port (e.g. \"http://0.0.0.0:8100\")\n                    index (int): Subtest index, starting at zero after 'begin' and incrementing with each call to subtest.\n            Returns:\n                    tuple ((bool, str, bool)):\n                        True if test passed,\n                        A human-readable description of the result (for logging),\n                        True to continue running tests.\n            \"\"\"\nmax_iter = 9\ntest_inputs = [1,2,3,4,5,6,7,8,9,10]\nlogger.debug(\nf\"MyApp test index={index} out of {max_iter}\"\n)\ntest_input = test_inputs[index]\nurl = f\"{ipaddr}/tested_endpoint/\"\nparams = {\"x\": f\"{test_input}\"}\nresponse = session.post(url, params=params, headers={\"accept\": \"application/json\"}, timeout=5\n)\ndef eval_result(response):\nif response.status_code == 200:\nreturn (True, \"Test passed\")\nelse\nreturn (False, \"Test failed\")\nstatus, message = eval_result(response)\nif index &gt;= max_iter:\n# stop testing\nreturn (status, message, False)\nelse:\n# continue testing\nreturn (status, message, True)\ndef end(self, session, ipaddr: str) -&gt; int:\n\"\"\"\n            End application testing.\n                    session: The Python requests library session (credentials are initialised before calling into application tests).\n                    ipaddr (str): IP address including port (e.g. \"http://0.0.0.0:8100\")\n            Returns:\n                    0 if successful.\n            \"\"\"\nlogger.info(\"MyApp test ends\")\nreturn 0\ndef create_ssf_application_test_instance(ssf_config: SSFConfig) -&gt; SSFApplicationTestInterface:\nlogger.info(\"Create a test instance\")\nreturn MyTestClient()\n</code></pre> <p>The method <code>subtest</code> will run in a loop as long as the last value of the output tuple is <code>True</code>. For each iteration, the input <code>index</code> is incremented. Additional checks can be written in the <code>begin</code> and <code>end</code> methods. Note that you also need to define the builder <code>create_ssf_application_test_instance</code> to enable SSF to get the instance. SSFConfig object passed to the test instance factory captures as a copy both the current ssf config and run-time arguments in a single structure and is provided as additional context for the test.</p>"},{"location":"advanced/#check-the-available-ipus","title":"Check the available IPUs","text":"<p>SSF provides a few utilities that you can use when implementing <code>SSFApplicationInterface</code>, You can use <code>get_ipu_count</code> to check how many IPUs are available on the system where your application is executed. <pre><code>from ssf.utils import get_ipu_count\n</code></pre></p>"},{"location":"advanced/#building-an-ssf-image","title":"Building an SSF image","text":"<p>SSF can self package:</p> <p><pre><code>gc-ssf package\n</code></pre> The diagram below shows what happens when this command is run:</p> <p></p> <p>The resulting SSF image can be run as an interactive Bash session:</p> <pre><code>gc-docker -- --rm -it --entrypoint bash graphcore/simple-server-framework:latest\n</code></pre> <p>Or it can be used to start an application dynamically by passing options with the SSF_OPTIONS environment variable. The following example shows how the SSF container might be used for rapid deployment of an application:</p> <pre><code>gc-docker -- --rm -d  --env SSF_OPTIONS='--config git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml init build run' graphcore/simple-server-framework:latest\n</code></pre>"},{"location":"advanced/#building-the-wheel-from-sources","title":"Building the wheel from sources","text":"<p>Build the wheel:</p> <pre><code>python -m build\n</code></pre>"},{"location":"advanced/#installing-the-built-wheel","title":"Installing the built wheel","text":"<p>Then install the wheel:</p> <pre><code>python3 -m venv .ssfenv\n. .ssfenv/bin/activate\npip install dist/ssf*.whl\n</code></pre>"},{"location":"advanced/#running-the-cli-from-python","title":"Running the CLI from Python","text":"<p>You can run the SSF CLI from Python. For example:</p> <pre><code>from ssf import cli as ssf_cli\nssf_cli.run([\"--config\", \"examples/simple/ssf_config.yaml\", \"init\", \"build\", \"run\"])\n</code></pre>"},{"location":"all_options/","title":"Options","text":"<p>"},{"location":"all_options/#cli-options","title":"CLI Options","text":""},{"location":"all_options/#general-options","title":"General options:","text":"<ul> <li><code>-a</code> {fastapi}, <code>--api</code> {fastapi}                         Which API framework to use (default: fastapi)  </li> <li><code>--add-ssh-key</code> ADD_SSH_KEY                         Add an SSH key (for example for a remote repo).                         Provide the key in an environment variable and specify the environment variable name with this argument.                         Multiple keys can be added if necessary. Keys are added before any other commands are processed. (default: None)  </li> <li><code>--file-log-level</code> {DEBUG,INFO,WARNING,ERROR,CRITICAL}                         Set file log level. (default: DEBUG)  </li> <li><code>--stdout-log-level</code> {DEBUG,INFO,WARNING,ERROR,CRITICAL}                         Set stdout log level. (default: INFO)  </li> </ul>"},{"location":"all_options/#runtime-gc-ssf-run-options","title":"Runtime (gc-ssf run) options:","text":"<ul> <li><code>--host</code> HOST           Address to bind to (serve from) (default: 0.0.0.0)  </li> <li><code>-p</code> PORT, <code>--port</code> PORT  Port to bind to (serve from) (default: 8100)  </li> <li><code>-ra</code> REPLICATE_APPLICATION, <code>--replicate-application</code> REPLICATE_APPLICATION                         Number of application instances (default: 1)  </li> <li><code>-rs</code> REPLICATE_SERVER, <code>--replicate-server</code> REPLICATE_SERVER                         Number of server instances (default: 1)  </li> <li><code>-k</code> KEY, <code>--key</code> KEY     Secure the API with an API key. (default: None)  </li> <li><code>--watchdog-request-threshold</code> WATCHDOG_REQUEST_THRESHOLD                         Set threshold value in seconds for request duration. If exceeded the watchdog will restart the application.                         Value set to 0 (default) disables the request duration watchdog. (default: 0)  </li> <li><code>--watchdog-request-average</code> WATCHDOG_REQUEST_AVERAGE                         Set number of last requests included in calculating average watchdog request duration. (default: 3)  </li> <li><code>--batching-timeout</code> BATCHING_TIMEOUT                         Set how many seconds the server will wait to accumulate samples when batching is enabled. (default: 1)  </li> <li><code>--max-allowed-restarts</code> MAX_ALLOWED_RESTARTS                         Number of time a replica can fails successively on restart before going to an irrecoverable error state (default: 2)  </li> </ul>"},{"location":"all_options/#container-options-package-and-publish","title":"Container options (package and publish):","text":"<ul> <li><code>--package-baseimage</code> PACKAGE_BASEIMAGE                         Override default baseimage when packaging.                         The default baseimage is taken from the application config (application.package.docker.baseimage),                         or set to graphcore/pytorch:3.2.0-ubuntu-20.04-20230314. If PACKAGE_BASEIMAGE is specified then it overrides the default baseimage. (default: None)  </li> <li><code>--package-name</code> PACKAGE_NAME                         Override default bundle name when packaging or publishing. (default: None)  </li> <li><code>--package-tag</code> PACKAGE_TAG                         Override default image tag when packaging or publishing.                          Format: <code>--package-tag</code>  user/repo:tag (default: None)  </li> <li><code>--docker-username</code> DOCKER_USERNAME                         Username for login, if login to a docker repository is required when publishing.                         You can login to your docker server before running SSF if preferred, in which case this argument can be skipped.                         If login is required, both username and password must be specified, server is optional.                          (default: None)  </li> <li><code>--docker-password</code> DOCKER_PASSWORD                         Password for login, if login to a docker repository is required when publishing.                         You can login to your docker server before running SSF if preferred, in which case this argument can be skipped.                         If login is required, both username and password must be specified, server is optional.                          (default: None)  </li> <li><code>--container-server</code> CONTAINER_SERVER                         Server for login, if login to a container repository is required when publishing.                         You can login to your container server before running SSF if preferred, in which case this argument can be skipped.                         If login is required, both username and password must be specified, server is optional. (default: None)  </li> </ul>"},{"location":"all_options/#deployment-gc-ssf-deploy-options","title":"Deployment (gc-ssf deploy) options:","text":"<ul> <li><code>--deploy-platform</code> {Gcore}                         The target platform for deployment.                         Gcore deployments start or update a deployment at the specified remote target address using a simple bash boot script and ssh. (default: Gcore)  </li> <li><code>--deploy-name</code> DEPLOY_NAME                         The deployment name (defaults to application ID if not specified). (default: None)  </li> <li><code>--deploy-package</code>      The default is to deploy an SSF container and dynamically build and run the application from within the SSF container.                         Use this option to instead deploy the application's pre-packaged and published container. (default: False)  </li> <li><code>--deploy-gcore-target-username</code> DEPLOY_GCORE_TARGET_USERNAME                         Gcore: The target username with which to launch the deployment. (default: None)  </li> <li><code>--deploy-gcore-target-address</code> DEPLOY_GCORE_TARGET_ADDRESS                         Gcore: The target address with which to launch the deployment. (default: None)  </li> </ul>"},{"location":"all_options/#test-gc-ssf-test-options","title":"Test (gc-ssf test) options:","text":"<ul> <li><code>--test-skip-stop</code>      Don't stop the application container after running 'test'. (default: False)  </li> <li><code>--test-skip-start</code>     Don't start the application container before running 'test' (assume it is already running). (default: False)  </li> </ul>"},{"location":"features/","title":"Features","text":""},{"location":"features/#features","title":"Features","text":""},{"location":"features/#running-an-application-from-a-remote-repository","title":"Running an application from a remote repository","text":"<p>The config can specify a remote application with the syntax: <pre><code>`git@&lt;remote&gt;|&lt;config yaml path&gt;`\n`git@&lt;remote&gt;@&lt;branch&gt;|&lt;config yaml path&gt;` # to use a branch\n`git@&lt;remote&gt;@&lt;sha&gt;|&lt;config yaml path&gt;` # to use commit hash\n</code></pre> If a config yaml file is not specified then the default <code>ssf_config.yaml</code> file (from the repo root) is used.</p> <p>The repo code is freshly cloned when <code>init</code> is issued. Code is pulled to CWD <code>.repo/&lt;repo name&gt;/...</code>  For example:</p> <p><pre><code>gc-ssf  --config 'git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml' init build run\n</code></pre> This will clone <code>simple-server-framework</code> to <code>.repo/simple-server-framework/...</code> and then build and run the <code>simple</code> example.</p>"},{"location":"features/#pinning-a-specific-branch-or-version","title":"Pinning a specific branch or version","text":"<p>You can also specify a branch or a commit hash. For instance: <pre><code>gc-ssf  --config 'git@github.com:username/my-repo.git@my-branch|path/to/ssf_config.yaml' init build run\n</code></pre></p> <p>This also works when using <code>deploy</code>. Check out this example for more details.</p>"},{"location":"features/#specifying-a-local-application-git-repository","title":"Specifying a local application git repository","text":"<p>You can specify a local repository during development or for testing (if running SSF locally). For instance: <pre><code>gc-ssf  --config 'file:///my-repo|path/to/ssf_config.yaml' init build run\n</code></pre></p>"},{"location":"features/#register-ssh-keys","title":"Register SSH keys","text":"<p>You can use SSH keys to deploy to a VM. SSH keys can be registered locally without specifying other commands; the key string needs to be stored in an enviroment variable, for example <code>ENV_KEY</code>:</p> <pre><code>gc-ssf --add-ssh-key ENV_KEY\n</code></pre>"},{"location":"features/#optional-api-key","title":"Optional API key","text":"<p>We advise you not to open the generated endpoints publicly, use dedicated services to secure them. SSF provides a minimal security layer, when using the command <code>run</code> you can decide to set a key.</p> <p>Use the <code>--key &lt;KEY&gt;</code> option to set an API key.</p>"},{"location":"features/#replication","title":"Replication","text":"<p>Replication provides a mechanism for scaling the whole application. Replication levels can be used individually or stacked together depending on the required use case.</p>"},{"location":"features/#dispatcher-replication","title":"Dispatcher replication","text":"<p>Use the <code>--replicate-application &lt;N&gt;</code> option to create multiple application instances within one server instance. There will be <code>&lt;N&gt;</code> calls to <code>create_ssf_application_instance</code> from one server instance. Incoming requests will be put in an internal FIFO queue and therefore will be handled in the order they were received.</p> <p>Choose this mechanism for applications where the average time spent on request handling (on IPUs) is significantly higher than the time spent on receiving the request and preparing the data.</p>"},{"location":"features/#server-replication","title":"Server replication","text":"<p>Use the <code>--replicate-server &lt;K&gt;</code> option to create multiple server instances.</p> <p>NOTE: The value of <code>&lt;K&gt;</code> should not be higher than the number of processor cores on the machine that is used to run the server. Setting this value higher will cause performance degradation.</p> <p>There will be <code>&lt;K&gt;</code> server instances working in <code>&lt;K&gt;</code> separate processes. Incoming requests will be assigned a process by the OS scheduler mechanism. This mechanism will generally choose a process that is waiting on I/O or not consuming CPU resources.</p> <p>Choose server replication if the processor cores are likely to spend more time receiving the request and preparing the data than the amount of time the IPUs spend processing the input.</p>"},{"location":"features/#stacking-replication-mechanism","title":"Stacking replication mechanism","text":"<p>In some cases it may useful to use both these replication mechanisms (dispatcher and server) together. It should be noted that the number of occupied IPUs in a ready state can be calculated using this formula:</p> <p>IPUs = I * K * N</p> <p>where:</p> <ul> <li>I is the number of IPUs used by one application instance</li> <li>K is <code>&lt;K&gt;</code> used as value for <code>--replicate-server &lt;K&gt;</code></li> <li>N is <code>&lt;N&gt;</code> used as value for <code>--replicate-application &lt;N&gt;</code></li> </ul> <p>If the required number of IPUs are not available then the server will fail to boot.</p>"},{"location":"features/#application-generic-health-check","title":"Application generic health check","text":"<p>Applications can expose a custom health check which is being monitored by the SSF server. For details see <code>is_healthy</code> application's interface details.</p>"},{"location":"features/#batching","title":"Batching","text":"<p>Applications may benefit from being able to process multiple inputs at once. For this purpose <code>max_batch_size</code> may be set in your SSF config and this will instruct the server to accumulate user requests into batches of the defined maximal batch size. When set, applications will receive (through a <code>request</code> api) a list of size <code>J</code> containing &lt;1,<code>max_batch_size</code>&gt; dictionaries structured as defined in the SSF config. In this case the SSF server expects this function to return <code>J</code> dictionaries structured as defined in the SSF config.</p> <p>NOTE: The order of the output results should match the order of the input samples in the batch.</p> <p>A server batching timeout can be set using the <code>--batching-timeout &lt;T&gt;</code> run option. The server will wait a maximum of <code>&lt;T&gt;</code> seconds to accumulate up to <code>max_batch_size</code> samples. After <code>&lt;T&gt;</code> seconds have elapsed after receiving the first sample of the batch, the server will send as many samples as it has accumulated.</p> <p>When <code>max_batch_size</code> is not set a batch size of 1 is assumed.</p>"},{"location":"features/#health-probes","title":"Health probes","text":"<p>The SSF server implements <code>health/</code> probes that can be used for higher level monitoring. The three probes available that can be pinged by the GET method are:</p> <ul> <li><code>health/startup</code>:(200:success, other:failure) Succeed as soon as the server has started.</li> <li><code>health/live</code>: (200:success, other:failure) Liveness probe. Succeed as long as your server is alive. Failing liveness means that an irrecoverable error happened and the container should be restarted. Example one: Your application crashed during startup, liveness should then be down. Example 2: Your application has been running for some time and you have set the option <code>--max-allowed-restarts</code> to 5. If your application crashes and keeps crashing on restart, after 5 attempts by the watchdog mechanism you will have exceeded the <code>max-allowed-restarts</code> and liveness will be down.</li> <li><code>health/ready</code>: (200:success, other:failure). Readiness probe. Returns 200 as soon as your application is ready to receive requests. Typically returns 200 when at least one replica is ready.</li> </ul>"},{"location":"features/#watchdog","title":"Watchdog","text":"<p>The SSF server provides watchdog capabilities to handle application runtime problems by detecting bad states and restarting the application under defined conditions.</p>"},{"location":"features/#runtime-generic-watchdog","title":"Runtime generic watchdog","text":"<p>This is an internal server watchdog which detects if an application's process exists (regardless of the reason) and will restart the process if it has stopped.</p>"},{"location":"features/#request-duration-watchdog","title":"Request duration watchdog","text":"<p>The server can monitor request duration and restart the application if the averaged request duration time exceeds requested threshold. This feature can be set using the following run options:</p> <ul> <li><code>--watchdog-request-threshold &lt;T&gt;</code> float value T sets a threshold in seconds. Default value is 0 which disables the request duration watchdog.</li> <li><code>--watchdog-request-average &lt;A&gt;</code> integer A defines the number of last requests included in calculating the average watchdog request duration.</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#installing-ssf-as-a-cli-from-the-repo","title":"Installing SSF as a CLI from the repo","text":"<p>Using PyPI:</p> <pre><code>pip install git+ssh://git@github.com/graphcore/simple-server-framework.git\n</code></pre> <p>Now you will be able to run <code>gc-ssf</code>.</p>"},{"location":"installation/#running-ssf-from-source","title":"Running SSF from source","text":"<p>To run SSF from source you need to follow these steps.</p>"},{"location":"installation/#clone-the-repo","title":"Clone the repo","text":"<p>First you will need to clone the repo: <pre><code>git clone git@github.com:graphcore/simple-server-framework.git\n</code></pre></p>"},{"location":"installation/#create-a-virtual-environment","title":"Create a virtual environment","text":"<p>Then create a virtual environment: <pre><code>python3 -m venv .ssfenv\n</code></pre></p>"},{"location":"installation/#activate-the-virtual-environment","title":"Activate the virtual environment","text":"<p>You can then activate the virtual environment: <pre><code>. .ssfenv/bin/activate\npip install -e simple-server-framework/\n</code></pre></p>"},{"location":"installation/#for-ipu-users","title":"For IPU users","text":"<p>If you want to build applications for IPUs, you also need to install the Poplar SDK from the Graphcore download portal.</p>"},{"location":"installation/#using-ssf-from-the-public-docker-container","title":"Using SSF from the public Docker container.","text":"<p>SSF is available as a container. It can be deployed on a remote target as a server (see this example. But can also be used to develop locally:</p> <pre><code>docker pull docker.io/graphcore/simple-server-framework\n</code></pre> <p>To use it as an interactive bash session: <pre><code>docker run --rm -it --network host --entrypoint bash graphcore/simple-server-framework:latest\n</code></pre></p> <p>Alternatively, you can also execute a single SSF command by passing all arguments to the container via the environment variable SSF_OPTIONS: <pre><code>docker run --rm -d --network host --env SSF_OPTIONS='--config git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml init build run' --name simple-server-framework graphcore/simple-server-framework:latest\n</code></pre></p> <p>For IPU users: If your local system has IPUs and you want your container to access them, you may want to use <code>gc-docker</code>. Alternatively, just pass these additional arguments to <code>docker run</code> (<code>IPUOF_VIPU_API_HOST</code> and <code>IPUOF_VIPU_API_PARTITION_ID</code> should be configured properly on your system): <pre><code>--ulimit memlock=-1:-1 --net=host --cap-add=IPC_LOCK --device=/dev/infiniband/ -e IPUOF_VIPU_API_HOST=$IPUOF_VIPU_API_HOST -e IPUOF_VIPU_API_PARTITION_ID=$IPUOF_VIPU_API_PARTITION_ID-8 --ipc=host\n</code></pre></p>"},{"location":"model_format/","title":"Model format","text":""},{"location":"model_format/#model-format","title":"Model format","text":"<p>SSF is framework agnostic and does not enforce a specific model serialization format. The only restriction is that your ML model must be callable from Python. Here we describe how to adapt any ML model so it can be used in SSF.</p>"},{"location":"model_format/#create-an-application-interface","title":"Create an application interface","text":"<p>Create a Python file local to your application code. In that file, create an application specific concrete class inheriting from <code>SSFApplicationInterface</code>: <pre><code>from ssf.application import SSFApplicationInterface\nclass MyApplication(SSFApplicationInterface):\n...\n</code></pre> Implement the required methods: <pre><code>class MyApplication(SSFApplicationInterface):\ndef build(self) -&gt; int:\n\"\"\"\n        Build required dependencies.\n        This could be building custom-ops, binary executables, model-preprocessing, and so on.\n        Consider running the model to capture a PopEF file as an optimisation.\n        This is called when `gc-ssf build` is issued.\n        Returns:\n                0 if successful.\n        \"\"\"\ndef startup(self) -&gt; int:\n\"\"\"\n        One-time startup for the application instance.\n        Consider priming the application instance by issuing a dummy request.\n        This is called during `gc-ssf run` before requests are started.\n        Returns:\n                0 if successful.\n        \"\"\"\ndef request(\nself, params: Union[dict, list], meta: Union[dict, list]\n) -&gt; Union[dict, list]:\n\"\"\"\n        Request for inference.\n        This is called by the dispatcher for each queued request while `gc-ssf run` is running.\n        Parameters:\n                params (dict | list): Input parameters as a dictionary. Dictionary fields must match inputs declared in the SSF config.\n                meta (dict | list): Metadata fields such as `endpoint_id`, `endpoint_version` and `endpoint_index` to support multiple or versioned endpoints.\n        Returns:\n                Output parameters as a dictionary or list of dictionaries. Dictionary fields must match outputs declared in the SSF config.\n        Note:\n                When `max_batch_size` in the SSF config is greater than 1 then input parameters will be a list of dictionaries and the respective return values must be a list of dictionaries.\n        \"\"\"\ndef shutdown(self) -&gt; int:\n\"\"\"\n        One-time shutdown for the application instance.\n        This is called during `gc-ssf run` when requests are stopped.\n        Returns:\n                0 if successful.\n        \"\"\"\ndef is_healthy(self) -&gt; bool:\n\"\"\"\n        Called periodically, reports application specific unrecoverable failures.\n        Returning false will cause the server to restart the application replica.\n        When no specific errors can be detected or they are handled internally then the default implementation can be used.\n        Returns:\n                True during correct runtime, False otherwise\n        \"\"\"\nreturn True\n</code></pre> Then, add a factory method named <code>create_ssf_application_instance</code> that will create and return an <code>SSFApplicationInterface</code> instance:</p> <p><pre><code>def create_ssf_application_instance() -&gt; SSFApplicationInterface`\nreturn MyApplication()\n</code></pre> See <code>examples/simple/my_application.py</code> for more details.</p>"},{"location":"model_format/#optional-return-code","title":"(Optional) Return code","text":"<p>When you implement <code>SSFApplicationInterface</code> methods, you can use <code>ssf.results</code> to set a return code for the <code>build</code> methods  . <pre><code>from ssf.results import *\n</code></pre> Available return codes: <pre><code>RESULT_OK = 0\nRESULT_BAD_ARG = 1\nRESULT_FAIL = 2\nRESULT_SKIPPED = 255\n</code></pre></p>"},{"location":"model_format/#create-an-ssf-config","title":"Create an SSF Config","text":"<p>Create an SSF config <code>ssf_config.yaml</code> file next to your application code (where you created the application interface module).</p> <p>See <code>examples/simple/ssf_config.yaml</code> for more details.</p> <p>Your SSF config file should define the version of SSF for which this config was written and tested. For example:</p> <pre><code>ssf_version: 1.0.0\n</code></pre> <p>It should also include top-level application details, for example:</p> <p><pre><code>application:\nid: simple_test\nname: Test API\ndesc: A very simple test API.\nversion: 1.0\nmodule: my_application.py\ndependencies:\npython: ~\npoplar: [3.2.0]\ntrace: True\nartifacts: []\npackage:\ninclusions: []\nexclusions: []\nname: \"{{application.id}}.tar.gz\"\ntag: \"my-repo/{{application.id}}:{{application.version}}\"\nmax_batch_size: 1\nipus: 1\nstartup_timeout: 60\n</code></pre> Where:</p> <ul> <li><code>id</code>: (<code>str</code>) Unique identifier for the application (no spaces)</li> <li><code>name</code>: (<code>str</code>) Human readable one-liner title</li> <li><code>desc</code>: (<code>str</code>) Human readable expanded description</li> <li><code>version</code>: (<code>str</code>) Application-specific versioning</li> <li><code>license_name</code>: (<code>str</code>) Optional, license type/name for the application (model or API)</li> <li><code>license_url</code>: (<code>str</code>) Optional, url to the license for the application (model or API)</li> <li><code>terms_of_service</code>: (<code>str</code>) Optional, url to terms of service for the application (model or API)</li> <li><code>module</code>: (<code>str</code>) The name of your application module in which <code>create_ssf_application_instance</code> can be found</li> <li><code>dependencies\\python</code>: <code>(Array[str] | str)</code>A comma-separated package list or requirements file path</li> <li><code>dependencies\\poplar</code>: <code>(Array[str])</code> If declared, then a list of Poplar versions for which the application can run</li> <li><code>trace</code>: <code>bool</code> True to enable endpoint logging</li> <li><code>artifacts</code>: <code>(Array[str])</code> A list of 'globs' for files that are built when 'build' is issued (these are what 'init' will remove)</li> <li><code>package\\inclusions</code>: <code>(Array[str])</code> A list of 'globs' for application-specific files that should be included when packaging</li> <li><code>package\\exclusions</code>: <code>(Array[str])</code> A list of 'globs' for application-specific files that should be excluded when packaging</li> <li><code>package\\name</code>: <code>(str)</code> Filename for package bundle (tar.gz); if not specified then defaults to <code>&lt;application.name&gt;.&lt;application.version&gt;.tar.gz</code></li> <li><code>package\\tag</code>: <code>(str)</code> Tag for package image; if not specified then defaults to <code>&lt;application.name&gt;:&lt;application.version&gt;</code></li> <li><code>max_batch_size</code>: <code>(int)</code> Optional, defaults to 1; integer specifying maximal batch size supported by application; for more details see batching</li> <li><code>ipus</code> : <code>(int)</code> The number of IPUs required to run one instance of the application; if not specified then SSF assumes IPU is not strictly required</li> <li><code>startup_timeout</code>: <code>(int)</code> When testing, how many seconds to wait for container to be ready</li> <li><code>http_param_format:</code> <code>(str)</code> Enforce to use Query (use <code>query</code>) or Body (use <code>json</code>) parameters to pass input data. More details in the section Requests data format.</li> </ul> <p>You should also add a list of endpoints. Multiple endpoints can be declared.</p> <p>These may have the same (if only version is changing) or different IDs. Calls to the application request interface include metadata such as the endpoint ID, version and list index.</p> <p>For example:</p> <p><pre><code>endpoints:\n- id: Test1\nversion: 1\ndesc: Test1\ncustom: ~\n</code></pre> Where:</p> <ul> <li><code>id</code>: (<code>str</code>) Endpoint unique id (no spaces)</li> <li><code>version</code>: (<code>str</code>) Endpoint version</li> <li><code>desc</code>: (<code>str</code>) Human readable description</li> <li><code>custom</code>: (<code>str</code>) A Python file to import that contains the endpoint implementation (for example a FastAPI endpoint)</li> </ul> <p>If you don\u2019t specify an endpoint file to import with the <code>custom</code> option (using '~' instead, as in our example above) then the endpoint code is automatically generated as:</p> <p><code>/v&lt;version&gt;/&lt;id&gt;</code></p> <p>For example, if <code>version</code> is <code>1</code> and <code>id</code> is <code>my_endpoint</code>, then it will generate:</p> <p><code>/v1/my_endpoint</code></p> <pre><code>    inputs:\n- id: x:\ntype: Integer\ndesc: A value\noutputs:\n- id: requests:\ntype: Integer\ndesc: Count of requests.\n- id: x_times_1000:\ntype: Integer\ndesc: Input value x times 1000.\n</code></pre> <p>Where:</p> <ul> <li><code>id</code>:  Parameter id (name)</li> <li><code>type</code>: Type (one of the SSF defined types)</li> <li><code>desc</code>: Human readable one-liner description</li> </ul> <p>The <code>inputs</code> and <code>outputs</code> sections contain the parameters for the endpoint and user's application, respectively.</p> <p>SSF will code-generate the server endpoint for the inputs/outputs and map it through the user application <code>request</code> function provided in the <code>SSFApplicationInterface</code> instance (that will have been created by the <code>create_ssf_application_instance</code> call).</p> <p>NOTES:</p> <ul> <li> <p>The SSF config yaml file supports self-reference expansion for string entries; so, for our example, \"{{application.id}}.tar.gz\" would expand to \"simple_test.tar.gz\".</p> </li> <li> <p>The SSF config folder can be considered the primary application folder or context. All files and modules should be specified relative to the SSF config folder. The current working directory will be set to the application module folder before SSF calls any of the application entry points (<code>build</code> or <code>request</code> etc.).</p> </li> </ul>"},{"location":"model_format/#requests-data-format","title":"Requests data format","text":"<p>SSF will declare inputs to be delivered in the request body parameters (json) by default. The exceptions are:</p> <ul> <li>If <code>http_param_format: query</code> is declared in the SSF config for the end point, or</li> <li>If the end-point includes a custom input type (such as TempFile).</li> </ul> <p>In these cases SFF will declare inputs to be delivered query parameters. You might use <code>http_param_format: query</code> in your SSF config to force query-in-request-params. Note that using query parameters for long inputs is not recommended, this can cause unwanted behaviour due to URL size https://stackoverflow.com/questions/417142/what-is-the-maximum-length-of-a-url-in-different-browsers/417184#417184.</p>"},{"location":"model_format/#ssf-types","title":"SSF types","text":""},{"location":"model_format/#basic-types","title":"Basic types","text":"<p>The following basic types are supported:</p> ssf_config.yml expected Python type (in app) <code>String</code> <code>str</code> <code>Integer</code> <code>int</code> <code>Float</code> <code>float</code> <code>Boolean</code> <code>bool</code> <p>Note: For requests, basic type inputs are passed as query parameters.</p>"},{"location":"model_format/#list-types","title":"List types:","text":"<p>List types can also be used as a single input/output:</p> ssf_config.yml expected Python type (in app) <code>ListString</code> <code>List[str]</code> <code>ListInteger</code> <code>List[int]</code> <code>ListFloat</code>: <code>List[float]</code> <code>ListBoolean</code> <code>List[bool]</code> (Experimental) <code>ListAny</code> <code>list</code>"},{"location":"model_format/#input-file-handling","title":"Input file handling","text":"<p>The following file handling types are supported as input:</p> <ul> <li><code>TempFile</code> (input only): This supports upload of file over interface, the file is saved in the server (temporary) and queued to the request as a filename.</li> </ul>"},{"location":"model_format/#specialised-types","title":"Specialised types","text":"<ul> <li><code>PngImageBytes</code> (output only): This can be used to return a PNG image as content with media_type=\"image/png\".</li> </ul>"},{"location":"quickstart/","title":"Quick start","text":""},{"location":"quickstart/#quickstart","title":"Quickstart","text":"<p>Install gc-ssf:</p> <pre><code>pip install git+ssh://git@github.com/graphcore/simple-server-framework.git\n</code></pre> <p>Run the example:</p> <pre><code>gc-ssf  --config 'git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml' init build run\n</code></pre> <p>Look for lines in output, similar to:</p> <pre><code>2023-04-06 14:54:19,560 1392096    INFO      &gt; Starting fastapi runtime with examples/simple/ssf_config.yaml (run.py:25)\n2023-04-06 14:54:19,563 1392096    INFO      &gt; Address 10.129.96.101:8100 (run.py:29)\n</code></pre> <p>Use a browser to open the endpoint docs with the format <code>http://&lt;address&gt;/docs</code>, for example <code>http://10.129.96.101:8100/docs</code>.</p>"},{"location":"usage/","title":"CLI Usage","text":""},{"location":"usage/#cli-usage","title":"CLI usage","text":"<p>The SSF command line interface consists of the following main commands and a <code>--config</code> path.</p> <ul> <li>init</li> <li>build</li> <li>run</li> <li>package</li> <li>publish</li> <li>deploy</li> <li>test</li> </ul> <p>These commands can be used with various options.</p> <p>The format is: <pre><code>gc-ssf --config &lt;ssf-config-path&gt; COMMAND [options]\n</code></pre> Multiple commands can be used within the same line: <pre><code>gc-ssf --config &lt;ssf-config-path&gt; COMMAND1 COMMAND2 [options]\n</code></pre></p> <p>(Note: If <code>--config</code> is not defined, SSF will look for an <code>ssf_config.yaml</code> file in the current directory.)</p> <p>All ssf commands will return a status code defined in <code>ssf.results</code>: <pre><code>RESULT_OK = 0\nRESULT_BAD_ARG = 1\nRESULT_FAIL = 2\nRESULT_SKIPPED = 255\n</code></pre> If any command returns <code>RESULT_SKIPPED</code> (e.g. due to unsatisfied system requirements) then gc-ssf will return immediately and subsequents steps are cancelled. This can be useful in test pipelines where a test may then be marked as skipped instead of fail.</p>"},{"location":"usage/#ssf-init","title":"SSF init","text":"<p><code>init</code> is designed to set up a clean environment before you build. This will:</p> <ul> <li>Remove endpoint artifacts generated by a previous <code>build</code></li> <li>Remove custom <code>artifacts</code> (if any) specified in ssf_config.yaml</li> <li>Clone a repo if using a remote model repository</li> </ul> <p>For example: <pre><code># Example 1: remove all generated endpoint files related to ssf_config.yaml\ngc-ssf --config examples/simple/ssf_config.yaml init\n\n# Example 2: remove all generated endpoint files related to ssf_config.yaml\n# also clone a fresh copy of the remote repo git@github.com:graphcore/simple-server-framework.git\ngc-ssf --config 'git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml' init\n</code></pre></p>"},{"location":"usage/#ssf-build","title":"SSF build","text":"<p>This shows how to issue <code>build</code> for an example. This step will generate the API endpoint files. It will also instantiate the application and run the <code>build</code> method. You can use this to write custom preparation steps to run offline, for example  compilation, weights download, cache generation, and so on.</p> <p><pre><code>gc-ssf --config examples/simple/ssf_config.yaml build\n</code></pre> Example output: <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml build\n2023-03-28 16:40:20,893 644580     INFO      ==== Build ==== (build.py:15)\n2023-03-28 16:40:20,893 644580     INFO      &gt; Generate_endpoints (build.py:17)\n2023-03-28 16:40:20,898 644580     INFO      &gt; Load application (build.py:20)\n2023-03-28 16:40:20,898 644580     INFO      Creating application (application.py:95)\n2023-03-28 16:40:20,898 644580     INFO      Checking application dependencies (application.py:97)\n2023-03-28 16:40:20,898 644580     INFO      Loading simple_test application from /home/examples/simple/my_application.py with module id simple_test (application.py:103)\n2023-03-28 16:40:20,898 644580     INFO      loading module /home/examples/simple/my_application.py with module name simple_test (utils.py:110)\n2023-03-28 16:40:20,898 644580     INFO      Create MyApplication instance (my_application.py:34)\n2023-03-28 16:40:20,898 644580     INFO      &gt; Build application (build.py:23)\n2023-03-28 16:40:20,898 644580     INFO      Changed directory to /home/examples/simple (utils.py:123)\n2023-03-28 16:40:20,898 644580     INFO      MyApp build (my_application.py:14)\n2023-03-28 16:40:20,898 644580     INFO      Returned directory to /home (utils.py:127)\n</code></pre></p> <p>The endpoint files are auto-generated in the current working directory:</p> <pre><code>ssf_simple_test_endpoint_0_fastapi.py\nssf_simple_test_endpoint_1_fastapi.py\n</code></pre> <p>NOTE: Use <code>init</code> to remove build artifacts.</p>"},{"location":"usage/#ssf-run","title":"SSF run","text":"<p>Start running the server. It is assumed the endpoints already exist (=&gt; issue <code>build</code> first.)</p> <p>This shows how to issue <code>run</code> for an example.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml run\n</code></pre> <p>Example output:</p> <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml run\n2023-03-28 16:41:29,813 644749     INFO      ==== Run ==== (run.py:17)\n2023-03-28 16:41:29,813 644749     INFO      &gt; Starting fastapi runtime with examples/simple/ssf_config.yaml (run.py:28)\n2023-03-28 16:41:29,813 644749     INFO      &gt; Running Uvicorn (ssf_run.py:24)\n2023-03-28 16:41:29,989 644749     INFO      &gt; Running FastAPI server (server.py:27)\n2023-03-28 16:41:29,995 644749     INFO      &gt; Test API : A very simple test API (server.py:38)\n2023-03-28 16:41:29,996 644749     INFO      &gt; Creating FastAPI applications (server.py:43)\n2023-03-28 16:41:29,996 644749     INFO      &gt; Creating FastAPI instance (server.py:50)\n2023-03-28 16:41:29,997 644749     INFO      &gt; Loading endpoints for simple_test (server.py:79)\n2023-03-28 16:41:29,997 644749     INFO      &gt; Loading simple_test endpoint from /home/ssf_simple_test_endpoint_0_fastapi.py with module id simple_test_endpoint_0 (server.py:85)\n2023-03-28 16:41:29,997 644749     INFO      loading module /home/ssf_simple_test_endpoint_0_fastapi.py with module name simple_test_endpoint_0 (utils.py:110)\n2023-03-28 16:41:29,998 644749     INFO      Loaded /home/ssf_simple_test_endpoint_0_fastapi.py for simple_test endpoint (ssf_simple_test_endpoint_0_fastapi.py:33)\n2023-03-28 16:41:30,000 644749     INFO      &gt; Loading simple_test endpoint from /home/ssf_simple_test_endpoint_1_fastapi.py with module id simple_test_endpoint_1 (server.py:85)\n2023-03-28 16:41:30,000 644749     INFO      loading module /home/ssf_simple_test_endpoint_1_fastapi.py with module name simple_test_endpoint_1 (utils.py:110)\n2023-03-28 16:41:30,002 644749     INFO      Loaded /home/ssf_simple_test_endpoint_1_fastapi.py for simple_test endpoint (ssf_simple_test_endpoint_1_fastapi.py:33)\n2023-03-28 16:41:30,004 644749     WARNING   API key has not been specified, endpoints are not secured. (server.py:94)\n2023-03-28 16:41:30,005 644749     INFO      Started server process [644749] (server.py:74)\n2023-03-28 16:41:30,005 644749     INFO      Waiting for application startup. (on.py:48)\n2023-03-28 16:41:30,005 644749     INFO      &gt; Startup (server.py:106)\n2023-03-28 16:41:30,011 644815     INFO      Dispatcher started for simple_test [644749-&gt;644815] (dispatcher.py:59)\n2023-03-28 16:41:30,011 644815     INFO      &gt; Getting user application instance (dispatcher.py:64)\n2023-03-28 16:41:30,011 644815     INFO      Creating application (application.py:95)\n2023-03-28 16:41:30,011 644815     INFO      Checking application dependencies (application.py:97)\n2023-03-28 16:41:30,011 644815     INFO      Loading simple_test application from /home/examples/simple/my_application.py with module id simple_test (application.py:103)\n2023-03-28 16:41:30,011 644815     INFO      loading module /home/examples/simple/my_application.py with module name simple_test (utils.py:110)\n2023-03-28 16:41:30,012 644815     INFO      Create MyApplication instance (my_application.py:34)\n2023-03-28 16:41:30,012 644815     INFO      instance=&lt;simple_test.MyApplication object at 0x7fc0503ab250&gt; (dispatcher.py:66)\n2023-03-28 16:41:30,012 644815     INFO      &gt; Initialising user application instance (dispatcher.py:69)\n2023-03-28 16:41:30,012 644815     INFO      MyApp initialise (my_application.py:18)\n2023-03-28 16:41:31,012 644749     INFO      Application startup complete. (on.py:62)\n2023-03-28 16:41:31,013 644749     INFO      Uvicorn running on http://0.0.0.0:8100 (Press CTRL+C to quit) (server.py:217)\n</code></pre> <p>It is valid to combine build and run in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml build run\n</code></pre>"},{"location":"usage/#ssf-package","title":"SSF package","text":"<p>This shows how to issue <code>package</code> for an example. It is assumed the endpoints already exist (=&gt; issue <code>build</code> first.)</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml package\n</code></pre> <p>This will pull resources into a local directory (<code>.package</code>) and build a docker image with name <code>&lt;application_id&gt;:latest</code></p> <p>Example output:</p> <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml package\n2023-03-28 21:03:52,071 1307287    INFO      ==== Package ==== (package.py:15)\n2023-03-28 21:03:52,071 1307287    INFO      &gt; Packaging simple_test to /home/.package (package.py:30)\n2023-03-28 21:03:52,072 1307287    INFO      &gt; Package SSF from /home/ssf (package.py:70)\n2023-03-28 21:03:52,077 1307287    INFO      &gt; Package Application from /home/examples/simple (package.py:86)\n2023-03-28 21:03:52,077 1307287    INFO      &gt; Package Endpoint files (package.py:90)\n2023-03-28 21:03:52,078 1307287    INFO      &gt; Generate docker image (package.py:126)\n2023-03-28 21:03:52,114 1307287    INFO      [Docker image build] Sending build context to Docker daemon  103.9kB (utils.py:73)\n2023-03-28 21:03:52,198 1307287    INFO      [Docker image build] Step 1/14 : FROM graphcore/pytorch:3.1.0-ubuntu-20.\n[...]\n2023-03-28 21:03:52,226 1307287    INFO      [Docker image build]  ---&gt; Using cache (utils.py:73)\n2023-03-28 21:03:52,226 1307287    INFO      [Docker image build]  ---&gt; 1a39476a9bb4 (utils.py:73)\n2023-03-28 21:03:52,226 1307287    INFO      [Docker image build] Step 14/14 : CMD cd src &amp;&amp; ./run.sh (utils.py:73)\n2023-03-28 21:03:52,227 1307287    INFO      [Docker image build]  ---&gt; Using cache (utils.py:73)\n2023-03-28 21:03:52,227 1307287    INFO      [Docker image build]  ---&gt; ed9945bd6e3a (utils.py:73)\n2023-03-28 21:03:52,228 1307287    INFO      [Docker image build] Successfully built ed9945bd6e3a (utils.py:73)\n2023-03-28 21:03:52,230 1307287    INFO      [Docker image build] Successfully tagged simple_test:latest (utils.py:73)\n2023-03-28 21:03:52,237 1307287    INFO      &gt; Run: 'docker run --rm -d --network host --name simple_test simple_test:latest' (package.py:137)\n2023-03-28 21:03:52,237 1307287    INFO      &gt; Logs: 'docker logs simple_test' (package.py:138)\n2023-03-28 21:03:52,237 1307287    INFO      &gt; Stop: 'docker stop simple_test' (package.py:139)\n</code></pre> <p>It is valid to combine build and package in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml build package\n</code></pre>"},{"location":"usage/#ssf-publish","title":"SSF publish","text":"<p>This shows how to issue 'publish' for an example.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml publish\n</code></pre> <p>This will push the most recent packaged docker image to a docker server (default Docker Hub).</p> <p>This assumes the docker server is already logged in, but if a docker username and password are provided, then these will be used to login before pushing. A specific server may also be specified if required using <code>--container-server</code>.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml --docker-username &lt;username&gt; --docker-password &lt;password&gt; publish\n</code></pre> <p>Example output:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml publish\n2023-04-11 17:41:36,382 1273566    INFO      &gt; Config examples/simple/ssf_config.yaml (cli.py:334)\n2023-04-11 17:41:36,387 1273566    INFO      &gt; ==== Publish ==== (publish.py:15)\n2023-04-11 17:41:37,212 1273566    INFO      &gt; Docker push user/myapp:simple_test-1.0-latest to DockerHub (publish.py:43)\n2023-04-11 17:41:37,252 1273566    INFO      [Push user/myapp:simple_test-1.0-latest] The push refers to repository [docker.io/user/myapp] (utils.py:193)\n2023-04-11 17:41:37,509 1273566    INFO      [Push user/myapp:simple_test-1.0-latest] 0f277cce0197: Preparing (utils.py:193)\n[...]\n2023-04-11 17:41:40,249 1273566    INFO      [Push user/myapp:simple_test-1.0-latest] simple_test-1.0-latest: digest:\nsha256:cb...0d6 size: 5996 (utils.py:193)\n</code></pre> <p>It is assumed the package already exist (=&gt; issue 'package' first.)</p> <p>It is valid to combine package and publish in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml package publish\n</code></pre>"},{"location":"usage/#ssf-deploy","title":"SSF deploy","text":"<p>This shows how to issue 'deploy' for an example. <pre><code>gc-ssf --config examples/simple/ssf_config.yaml [options] deploy\n</code></pre></p> <p>It is assumed the image already exists on Docker hub, two possibilities:</p> <ul> <li>You have packaged it yourself and used <code>publish</code> first, then use the option <code>--deploy-package</code> (see example 1)</li> <li>You use the public pre-build SSF image (see example 2)</li> </ul> <p>It is valid to combine publish and deploy in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml [options] publish deploy\n</code></pre>"},{"location":"usage/#deployment-to-gcore","title":"Deployment to Gcore","text":"<p>For Gcore the deployment commands are passed using SSH. So the required options will be:</p> <ul> <li><code>--deploy-platform</code> (Gcore)</li> <li><code>--deploy-gcore-target-address</code>: The Gcore VM IP address to SSH</li> <li><code>--deploy-gcore-target-username</code>: The Gcore VM username to SSH (by default VMs use <code>ubuntu</code>)</li> </ul> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml  --deploy-platform Gcore --deploy-gcore-target-address &lt;ipaddr&gt; --deploy-gcore-target-username &lt;username&gt; deploy\n</code></pre> <p>For example: <pre><code>gc-ssf deploy --config ssf_config.yaml --deploy-platform Gcore --port 8100 --deploy-gcore-target-address 123.456.789.0 --deploy-gcore-target-username ubuntu --docker-username dockerUser --docker-password my-docker-token --add-ssh-key KEY_ENV_VARIABLE --deploy-package\n</code></pre></p> <p>This will deploy the most recently published image to the target platform (Gcore).</p> <p>The config application ID is used for the deployment name unless <code>--deploy-name</code> is used to override it.</p> <p>This will create a new deployment or update an existing deployment if one already exists.</p> <p>The target must have already been created.</p> <p>Use <code>--add-ssh-key</code> to add an SSH key via environment variable if required.</p> <p>See <code>gc-ssf --help</code> for other <code>--deploy-</code> arguments.</p> <p>Some SSF options, such as <code>--port</code>, <code>--key</code>, <code>--replicate-application</code> and <code>--replicate-server</code> are passed through to the deployment with the image SSF_OPTIONS feature to configure the deployed instance(s).</p>"},{"location":"usage/#ssf-test","title":"SSF test","text":"<p>This shows how to issue 'test' for an example.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml test\n</code></pre> <p>This will start and test the current packaged Docker image (run <code>gc-ssf package</code> first.)\\</p> <p>2 types of test are issued:</p> <ul> <li>Built-in SSF tests (always run): Testing that the server runs normally (for instance accessing root endpoint)</li> <li>Custom tests (optional): Users can define their own tests to run with this command, see the section \"Create a test interface for your application\".</li> </ul> <p>If the current system can not satisfy the application dependency (for example the required Poplar version), then the test will be skipped and a warning will be logged.</p> <p>If IPUs are required then remember to set 'ipus' in the SSF config.</p> <p>Example output:</p> <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml test\n2023-05-04 10:33:04,800 1578140    INFO      &gt; Config examples/simple/ssf_config.yaml (cli.py:404)\n2023-05-04 10:33:04,805 1578140    INFO      &gt; ==== Test ==== (test.py:12)\n2023-05-04 10:33:04,805 1578140    INFO      &gt; Start simple-test user/repo:simple-test-1.0-latest (test.py:263)\n2023-05-04 10:33:04,871 1578140    INFO      SSF_OPTIONS=-p 8100 --key test_key (test.py:65)\n2023-05-04 10:33:05,118 1578140    INFO      &gt; Wait simple-test (test.py:276)\n2023-05-04 10:33:10,202 1578140    INFO      &gt; Subtest Check root endpoint (test.py:279)\n2023-05-04 10:33:10,223 1578140    INFO      &gt; Subtest Check security logout (test.py:286)\n2023-05-04 10:33:10,243 1578140    INFO      &gt; Subtest Check security forbidden (test.py:293)\n2023-05-04 10:33:10,260 1578140    INFO      &gt; Subtest Check security accepted (test.py:300)\n2023-05-04 10:33:10,277 1578140    INFO      OK 4 KO 0 (test.py:307)\n2023-05-04 10:33:10,324 1578140    INFO      &gt; Stop simple-test (test.py:314)\n2023-05-04 10:33:20,559 1578140    INFO      &gt; Remove simple-test (test.py:316)\n</code></pre> <p>It is assumed the package already exist (=&gt; issue 'package' first.)</p> <p>It is valid to combine package and test in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml package test\n</code></pre> <p>If the test passes, then <code>gc-ssf test</code> will return <code>RESULT_OK</code> (0).</p> <p>If the test is skipped (for example, due to configuration) then <code>gc-ssf test</code> will return <code>RESULT_SKIPPED</code> (255).</p> <p>If the test fails, then an exception will be thrown. Example: <pre><code>ValueError: simple-test failed testing OK:7 KO:1\n</code></pre></p>"},{"location":"walkthrough/","title":"Walkthrough","text":""},{"location":"walkthrough/#walkthrough","title":"Walkthrough","text":"<p>This walkthrough will show how to serve an application using SSF and deploy it on Gcore to use IPUs. As a prerequisite we need to follow the installation instructions to install and enable the Poplar SDK with Poptorch in the environment.</p>"},{"location":"walkthrough/#select-a-model","title":"Select a model","text":"<p>For this example we deploy a pre-trained question answering model from Huggingface. Distilbert-base-cased-distilled-squad will do the trick \ud83e\udd17 The model itself can be imported from the optimum-graphcore library as an inference pipeline: <pre><code>from optimum.graphcore import pipeline\nquestion_answerer = pipeline(\n\"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n)\n</code></pre> Note that the input is a dictionary containing <code>question</code> and <code>context</code> strings. The output is also a dictionary containing an <code>answer</code> string, the <code>score</code>, and the <code>start</code> and <code>end</code> positions of the answer in the <code>context</code> string.</p>"},{"location":"walkthrough/#implement-the-application-interface","title":"Implement the application interface","text":"<p>To interface our model with SSF we need to implement the application interface  <code>SSFApplicationInterface</code>. The following file <code>my_app.py</code> shows the code needed for this: <pre><code>from optimum.graphcore import pipeline\nimport logging\nfrom ssf.application import SSFApplicationInterface\nfrom ssf.utils import get_ipu_count\nfrom ssf.results import RESULT_OK\nlogger = logging.getLogger()\nclass MyApplication(SSFApplicationInterface):\ndef __init__(self):\nself.question_answerer: pipeline = None\nself.dummy_inputs_dict = {\n\"question\": \"What is your name?\",\n\"context\": \"My name is Rob.\",\n}\ndef build(self) -&gt; int:\nif get_ipu_count() &gt;= 2:\nlogger.info(\"Compiling model...\")\nbuild_pipeline = pipeline(\n\"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n)\nbuild_pipeline(self.dummy_inputs_dict)\nelse:\nlogger.info(\n\"IPU requirements not met on this device, skipping compilation.\"\n)\nreturn RESULT_OK\ndef startup(self) -&gt; int:\nlogger.info(\"App started\")\nself.question_answerer = pipeline(\n\"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n)\nself.question_answerer(self.dummy_inputs_dict)\nreturn RESULT_OK\ndef request(self, params: dict, meta: dict) -&gt; dict:\nresult = self.question_answerer(params)\nreturn result\ndef shutdown(self) -&gt; int:\nreturn RESULT_OK\ndef is_healthy(self) -&gt; bool:\nresult = self.question_answerer(self.dummy_inputs_dict)\nreturn result[\"answer\"] == \"Rob\"\ndef create_ssf_application_instance() -&gt; SSFApplicationInterface:\nreturn MyApplication()\n</code></pre></p> <p>Now let's explain this step-by-step.</p> <p>SSF will serve an instance of <code>MyApplication</code> (by calling <code>create_ssf_application_instance</code>). To implement the interface we need to define the 5 methods <code>build</code>, <code>startup</code>, <code>request</code>, <code>shutdown</code> and is <code>is_healthy</code>:</p> <ul> <li>In the <code>__init__</code> method we define a placeholder for the <code>question_answerer</code>. We also define a dummy input dictionary that will be used to test the pipeline. <pre><code>class MyApplication(SSFApplicationInterface):\ndef __init__(self):\nself.question_answerer: pipeline = None\nself.dummy_inputs_dict = {\n\"question\": \"What is your name?\",\n\"context\": \"My name is Rob.\",\n}\n</code></pre></li> <li>The <code>build</code> method is called when issuing gc-ssf build. It should contain any preliminary steps that we want to happen offline, before running the server. Since we are using IPUs, we can compile the model in advance to save time at server startup. To do that, we should call the <code>pipeline</code> object at least once (the first call triggers compilation). The IPU compilation generates a cache <code>exe_cache/</code>, we explain later how to package this cache alongside the server. HuggingFace libraries will also download and cache model weights. We may not have access to IPUs to run the <code>build</code> step outside of our deployment environment - we can check this by using the utility function <code>get_ipu_count</code>. If we don't have access to IPUs it will skip compilation which will then be triggered by <code>startup</code> when deployed. Note: we use <code>return RESULT_OK</code> from ssf return codes, this is equivalent to <code>return 0</code> <pre><code>    def build(self) -&gt; int:\nif get_ipu_count() &gt;= 2:\nlogger.info(\"Compiling model...\")\nbuild_pipeline = pipeline(\n\"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n)\nbuild_pipeline(self.dummy_inputs_dict)\nelse:\nlogger.info(\n\"IPU requirements not met on this device, skipping compilation.\"\n)\nreturn RESULT_OK\n</code></pre></li> <li>The <code>startup</code> method is called every time the server starts (when issuing gc-ssf run) so it can contain any warmup code we need. We instantiate and call the pipeline with dummy inputs: if the compilation cache exists, this first call will have the effect of attaching the model to available IPUs. If not, it will compile it first. Since the lifespan of <code>self.question_answerer</code> is the same as <code>MyApplication</code>, the model will stay attached to the IPUs as long as the <code>MyApplication</code> instance is alive. <pre><code>    def startup(self) -&gt; int:\nlogger.info(\"App started\")\nself.question_answerer = pipeline(\n\"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n)\nself.question_answerer(self.dummy_inputs_dict)\nreturn RESULT_OK\n</code></pre></li> <li>The <code>request</code> method is the function executed by our API call. It is important to understand what will be in the dictionaries <code>params</code>(the inputs) and <code>return</code>(the output) as SSF will use it later to generate the API. <pre><code>    def request(self, params: dict, meta: dict) -&gt; dict:\nresult = self.question_answerer(params)\nreturn result\n</code></pre></li> <li> <p>Any resource freeing can be carried out in the <code>shutdown</code> method. We have left it empty: <pre><code>    def shutdown(self) -&gt; int:\nreturn RESULT_OK\n</code></pre></p> </li> <li> <p>Finally, <code>is_healthy</code> will be called periodically by our server. If it fails, the server will try to kill and restart <code>MyApplication</code>. As an example we verify that we get an expected output from a known input: <pre><code>    def is_healthy(self) -&gt; bool:\nresult = self.question_answerer(self.dummy_inputs_dict)\nreturn result[\"answer\"] == \"Rob\"\n</code></pre></p> </li> </ul>"},{"location":"walkthrough/#write-ssf-config","title":"Write SSF config","text":"<p>The SSF config is the point of contact between our application and SSF. This will define all the metadata, the requirements (such as Python libraries needed for our application, the base Docker image to use, and so on), and also define our API.</p> <p>The SSF config folder can be considered the primary application folder or context. All files and modules should be specified relative to the SSF config folder. The current working directory will be set to the application module folder before SSF calls any of the application entry points (<code>build</code> or <code>request</code> etc.).</p> <p>Let's create <code>ssf_config.yaml</code> : <pre><code># Copyright (c) 2023 Graphcore Ltd. All rights reserved.\nssf_version: 1.0.0\napplication:\nid: qa_api\nname: Question Answering API\ndesc: A very simple QA API\nversion: 1.0\nmodule: my_app.py\nipus: 2\ntrace: True\nartifacts: []\ndependencies:\npython: git+https://github.com/huggingface/optimum-graphcore.git@97c11c3\npackage:\ninclusions: [exe_cache/]\nexclusions: []\ndocker:\nbaseimage: \"graphcore/pytorch:latest\"\nendpoints:\n- id: QA\nversion: 1\ndesc: Question answering model\ncustom: ~\ninputs:\n- id: context\ntype: String\ndesc: Context\n- id: question\ntype: String\ndesc: Question\noutputs:\n- id: answer\ntype: String\ndesc: Answer in the text\n- id: score\ntype: Float\ndesc: Probability score\n</code></pre></p> <p>Now let's explain the main lines:</p> <ul> <li> <p>Under <code>application</code>: <code>module</code> tells us where to find the interface that we have implemented: <pre><code>module: my_app.py\n</code></pre> Since we are using IPUs, let's check the resources used. The distillbert-base IPU config indicates 2 IPUs. With this config line, SSF will verify the system can acquire 2 IPUs when running the command <code>run</code> or <code>test</code>. <pre><code>ipus: 2\n</code></pre> Our model needs the <code>optimum-graphcore</code> package, we can specify any <code>pip</code> packages here (as a list or a requirements file path): <pre><code>dependencies:\n    python: git+https://github.com/huggingface/optimum-graphcore.git\n</code></pre> The <code>package</code> section refers to the gc-ssf package command, we can edit how we want SSF to build our container. We can include any files used by our application (and exclude some others), glob patterns are supported. Let's include the compilation cache. <pre><code>    inclusions: [exe_cache/]\n    exclusions: []\n</code></pre> Finally we want to use Graphcore's base image with pre-installed PyTorch, so we can run <code>optimum-graphcore</code> without issue: <pre><code>docker:\n        baseimage: \"graphcore/pytorch:latest\"\n</code></pre></p> </li> <li> <p>Under <code>endpoints</code>: This is how SSF will generate our API. <pre><code>id: QA\n    version: 1\n</code></pre> This endpoint path will be <code>v1/QA</code>. Now let's remember our application <code>request(self, params: dict, meta: dict)</code> method. We want to describe here the <code>inputs</code> dictionaries using the names of the keys (<code>context</code>, <code>question</code>) and ssf types. <pre><code>    inputs:\n      - id: context\n        type: String\n        desc: A context\n\n      - id: question\n        type: String\n        desc: The question\n</code></pre> We also want to describe the <code>outputs</code>. Notice we are only selecting <code>answer</code> and <code>score</code> from our results as we are not interested in returning the <code>start</code> and <code>end</code> keys. <pre><code>    outputs:\n\n      - id: answer\n        type: String\n        desc: Answer in the text\n\n      - id: score\n        type: Float\n        desc: Probability score\n</code></pre></p> </li> </ul> <p>Our application is officially ready!  Now let's see what SSF can do.</p>"},{"location":"walkthrough/#use-ssf","title":"Use SSF","text":"<p>We should now have the following file structure: <pre><code>project_directory/\n    - ssf_config.yaml\n    - my_app.py\n</code></pre> We can use the SSF commands for several different scenarios. First we should decide which commands we want to run locally (on our current machine) and which commands will run on the remote (deployment) machine.</p> <p>Let's look at a couple of examples.</p>"},{"location":"walkthrough/#example-1","title":"Example 1","text":"<p>In this first example we build our server locally and deploy its image via Docker Hub. The workflow can be summarised as follows: <pre><code>(local)-&gt; init, build, package, publish, deploy\n(remote)-&gt; run\n</code></pre></p> <ul> <li>The <code>init</code> and <code>build</code> steps are run locally, to compile the model before packaging.</li> <li>The <code>package</code> step creates the container image locally, and <code>publish</code> pushes it to Docker Hub.</li> <li>Finally <code>deploy</code> sends and executes the deployment script on our deployment target. In the previous step, the container image was packaged in such a way to ensure it executes <code>run</code> when started on the remote machine.</li> </ul> <p>Let's build our container: We use <code>--package-tag</code> to replace the tag from the config with our Docker username since we will push the image to Docker hub. <pre><code>gc-ssf init build package --config ssf_config.yaml --package-tag &lt;docker-username&gt;/&lt;repo-name&gt;\n</code></pre> The output should look like this: <pre><code>2023-05-30 17:52:10,773 1009745    INFO      &gt; Config ssf_config.yaml (cli.py:453)\n2023-05-30 17:52:10,778 1009745    WARNING   startup_timeout not specified in application. Defaulting to None (load_config.py:287)\n2023-05-30 17:52:10,778 1009745    WARNING   max_batch_size not specified in application. Defaulting to 1 (load_config.py:287)\n2023-05-30 17:52:10,778 1009745    WARNING   name not specified in application.package. Defaulting to Question answering API-1.0.tar.gz (load_config.py:287)\n2023-05-30 17:52:10,778 1009745    WARNING   run not specified in application.package.docker. Defaulting to  (load_config.py:287)\n2023-05-30 17:52:10,779 1009745    INFO      &gt; ==== Init ==== (init.py:17)\n2023-05-30 17:52:10,779 1009745    INFO      &gt; Cleaning_endpoints (init.py:19)\n2023-05-30 17:52:10,779 1009745    INFO      &gt; Clean application (init.py:22)\n2023-05-30 17:52:10,779 1009745    INFO      &gt; ==== Build ==== (build.py:25)\n2023-05-30 17:52:10,779 1009745    INFO      &gt; Generate_endpoints (build.py:39)\n2023-05-30 17:52:10,782 1009745    INFO      &gt; Load application (build.py:42)\n2023-05-30 17:52:10,782 1009745    INFO      Creating application interface (application.py:111)\n2023-05-30 17:52:10,782 1009745    INFO      Checking application dependencies (application.py:112)\n2023-05-30 17:52:10,782 1009745    INFO      installing python packages git+https://github.com/huggingface/optimum-graphcore.git (utils.py:139)\n2023-05-30 17:52:18,980 1009745    INFO      Loading Question answering API application from /home/repos/simple-server-framework/examples/walkthrough/my_app.py with module id Question answering API (application.py:119)\n2023-05-30 17:52:18,981 1009745    INFO      loading module /home/repos/simple-server-framework/examples/walkthrough/my_app.py with module name Question answering API (utils.py:161)\n[...]\n2023-05-30 17:52:25,540 1009745    INFO      instance=&lt;Question answering API.MyApplication object at 0x7f35c0027c70&gt; (build.py:45)\n2023-05-30 17:52:25,540 1009745    INFO      &gt; Build application (build.py:47)\n2023-05-30 17:52:25,540 1009745    INFO      Compiling model... (my_app.py:17)\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00]\n2023-05-30 17:52:32,930 1009745    INFO      &gt; ==== Package ==== (package.py:43)\n2023-05-30 17:52:32,930 1009745    INFO      &gt; Packaging Question answering API to /home/repos/simple-server-framework/examples/walkthrough/.package/Question answering API (package.py:66)\n2023-05-30 17:52:32,930 1009745    INFO      &gt; Package name Question answering API-1.0.tar.gz (package.py:67)\n2023-05-30 17:52:32,930 1009745    INFO      &gt; Package tag deployment-test:latest (package.py:68)\n2023-05-30 17:52:32,931 1009745    INFO      &gt; Package SSF from /home/repos/simple-server-framework/ssf (package.py:99)\n2023-05-30 17:52:32,941 1009745    INFO      &gt; Package Application from /home/repos/simple-server-framework/examples/walkthrough (package.py:136)\n2023-05-30 17:52:32,942 1009745    INFO      &gt; Package Endpoint files (package.py:150)\n2023-05-30 17:52:32,943 1009745    INFO      &gt; Gathering pip requirements (package.py:169)\n2023-05-30 17:52:32,943 1009745    INFO      &gt; Generate container image (package.py:211)\n[...]\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Package: (package.py:245)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Question answering API-1.0.tar.gz (from /home/repos/simple-server-framework/examples/walkthrough/.package/Question answering API/src) (package.py:246)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Test run: 'cd /home/repos/simple-server-framework/examples/walkthrough/.package/Question answering API/src &amp;&amp; ./run.sh' (package.py:247)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Docker: (package.py:249)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Run: 'docker run --rm -d --network host --name Question answering API deployment-test:latest' (package.py:250)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Run with IPU devices: 'gc-docker -- --rm -d  --name Question answering API deployment-test:latest' (package.py:253)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Logs: 'docker logs -f Question answering API' (package.py:257)\n2023-05-30 17:53:34,043 1009745    INFO      &gt; Stop: 'docker stop Question answering API' (package.py:258)\n</code></pre> You should be able to see that a new <code>.package/</code> directory has been created, it contains the bundled server. We can also verify that our server image was created during the package step with docker: <pre><code>docker images\n</code></pre> For the next step, a login to a Docker Hub registry is necessary. SSF will log in temporarily to Docker when using <code>--docker-username</code> and <code>--docker-password</code> options. But if you are already logged in with the correct account, you don't need these options for this step.</p> <p>We can now publish our image on Docker hub. Let's specify that we will push it with the same tag as during the package step using <code>--package-tag</code> <pre><code>gc-ssf publish --config ssf_config.yaml --package-tag &lt;docker-username&gt;/&lt;repo-name&gt; --docker-username &lt;docker-username&gt; --docker-password &lt;token&gt;\n</code></pre> Finally, deploy the container to Gcore. We will consider that we have set up a VM with at least 2 IPUs with the IP address 123.456.789.0 and the default username \"ubuntu\". To access it, we have a private key. SSF will need this to access the VM and deploy. To pass the key securely we will store it in an <code>env</code> variable and use the option <code>--add-ssh-key</code>. For instance we can set it from a file: <pre><code>SSH_KEY=$(cat ssh_key_file)  gc-ssf --add-ssh-key SSH_KEY\n</code></pre> Now let's run the <code>deploy</code> command with the following set of options. We also pass our Docker token via the option <code>--docker-password</code> which is needed to pull the image from our Docker hub repo to the remote VM (but this is not needed if you use a public repo). <pre><code>gc-ssf deploy --config ssf_config.yaml --deploy-platform Gcore --port 8100 --deploy-gcore-target-address 123.456.789.0 --deploy-gcore-target-username ubuntu --docker-username &lt;docker-username&gt; --docker-password &lt;token&gt; --package-tag &lt;username&gt;/&lt;repo-name&gt;:latest --deploy-package\n</code></pre> * Notice the use of <code>--deploy-packaged</code> to specify that we want to deploy from the package that we published previously.</p> <p>With this configuration our API endpoint should be available at <code>http://123.456.789.0:8100/v1/QA.</code> Since it's using FastAPI you can also test it with Swagger UI under the path <code>http://123.456.789.0:8100/docs</code>. Under the hood, the <code>deploy</code> command will simply run a script on the Gcore VM to pull our custom image from Docker Hub, build and run it. The container entry point will issue the command <code>run</code>.</p> <p>The following diagram summarises the operations of this first example. </p>"},{"location":"walkthrough/#example-2","title":"Example 2","text":"<p>Sometimes our local environment doesn't allow us to build containers, or we just want to experiment quickly. In this second example we won't build any container image. This means that the following workflow is possible: <pre><code>(local)-&gt; deploy\n(remote)-&gt; init, build, run\n</code></pre> This is made possible by storing our model in a repository and using a pre-built SSF image. First we need to set up a remote repository for our model. For example, using a GitHub account we could do: <pre><code>  cd project_directory &amp;&amp; git init\n  git add -A\n  git commit -m 'First commit'\ngit remote add origin git@github.com:your-username/project_directory.git\n  git push -u -f origin main\n</code></pre> To register the VM SSH key locally we could do: <pre><code>SSH_KEY=$(cat ssh_key_file)  gc-ssf --add-ssh-key SSH_KEY\n</code></pre></p> <p>If you use a private repo, you will also need to allow your VM to clone from it. To do that you will need to generate a GitHub deploy-key for your repo (or an equivalent access-limited SSH key). Then, pass it with the <code>deploy</code> command using an env variable (for example <code>MY_DEPLOY_KEY</code>) and <code>--add-ssh-key</code>.</p> <p>Now let's use <code>deploy</code> targeting our git repo: <pre><code>MY_DEPLOY_KEY=$(cat github_deploy_key) gc-ssf deploy --config 'git@github.com:your-username/project_directory.git|ssf_config.yaml' --port 8100  --deploy-platform Gcore --deploy-gcore-target-address 123.456.789.0 --deploy-gcore-target-username ubuntu --add-ssh-key MY_DEPLOY_KEY\n</code></pre></p> <ul> <li>Notice this time we are not using <code>--deploy-packaged</code>, so SSF will deploy from the default public image. <code>gc-ssf --help</code> can be used to see the default SSF image used for deployment. Under the hood the <code>deploy</code> command will send and run a script on the Gcore VM. That will pull the public SSF image from Docker Hub, build and run it. The container entry point will clone our repo and issue the three commands <code>init build run</code>.</li> </ul> <p>As in the first example, our API endpoint should be available at <code>http://123.456.789.0:8100/v1/QA</code>. You can also test it with Swagger UI under the path <code>http://123.456.789.0:8100/docs</code>.</p> <p>The following diagram summarises the operations of this second example. </p> <p>Note that we only deployed a Docker container on a Gcore VM. You can still SSH normally into your VM and use the usual Docker commands, for example <code>docker container ls</code>, <code>docker log...</code>, <code>docker stop ...</code>.</p>"},{"location":"walkthrough/#discussion-example-1-vs-example-2","title":"Discussion: Example 1 vs Example 2","text":"<p>These examples have shown two different ways to deploy on the Gcore platform with SSF. Both are serving your application with the same API, but it's important to underline their differences.</p>"},{"location":"walkthrough/#example-1-gives-you-more-control","title":"Example 1 gives you more control:","text":"<p>By packaging your app in advance with SSF, you create your own custom Docker image. Then you can version your images via Docker hub. This method can also have runtime advantages. By building and packaging some runtime-generated files in advance (such as IPUs pre-compiled executables) you can save some precious server startup time.</p>"},{"location":"walkthrough/#example-2-is-quicker-but-can-have-some-runtime-impact","title":"Example 2 is quicker but can have some runtime impact:","text":"<p>By deploying your model with the default public image, you don't need to run Docker locally or worry about the packaging step, and your model can be versioned via git. The server startup time might be impacted since the application <code>build</code> step will be triggered in the deployment environment before the server startup.  Of course, you can still include cached files as part of the model repository. But depending on the size of the files you might prefer to package your app in advance and follow Example 1, for instance if you have a very large model to compile.</p>"}]}
