{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is SSF?","text":""},{"location":"#simple-server-framework","title":"Simple Server Framework","text":""},{"location":"#documentation","title":"Documentation:","text":"<p>\ud83d\udcd6 SSF user guide</p>"},{"location":"#overview","title":"Overview","text":"<p>Graphcore's Simple Server Framework (SSF) is a tool for building, running and packaging (containerising) applications for serving. It can be used to serve any machine learning inference models running on IPUs and automate their deployment on supported cloud platforms.</p> <p>Using SSF simplifies deployment and reduces code repetition and redundancy when working with several independent applications.</p> <p>SSF has the following features:</p> <ul> <li>Minimal code required for applications</li> <li>Declarative configuration that is serving framework agnostic</li> <li>No specific machine learning model formats required</li> <li>Standardised application interface</li> <li>Serving framework implementation details are retained by SSF</li> </ul>"},{"location":"#basics","title":"Basics","text":"<p>Each application requires two things:</p> <ul> <li>An application interface (Python module to receive 'build' and 'run' requests)</li> <li>A declarative configuration that provides some details, including a definition of request inputs and outputs.</li> </ul> <p>Once the application interface and configuration have been set up then SSF can be used with the following commands (note that these commands can be issued individually or combined):</p> <ul> <li><code>init</code></li> <li><code>build</code></li> <li><code>run</code></li> <li><code>package</code></li> <li><code>publish</code></li> <li><code>deploy</code></li> </ul> <p>As an example, if you run:</p> <p><pre><code>gc-ssf --config examples/simple/ssf_config.yaml init build package\n</code></pre> you will create a clean packaged application with served endpoints. To take another example, if you run:</p> <p><pre><code>gc-ssf --config examples/simple/ssf_config.yaml build run\n</code></pre> you will build and run the application with served endpoints from source.</p>"},{"location":"advanced/","title":"Advanced","text":""},{"location":"advanced/#advanced","title":"Advanced","text":""},{"location":"advanced/#create-a-test-interface-for-your-application","title":"Create a test interface for your application","text":"<p>You can define a series of tests for your application. Such tests will be run when issuing the command <code>test</code>. The logic is similar to the application interface - you need to define a test client. This is a handler for a Python requests <code>session</code>. When running <code>gc-ssf test</code> an instance of your server will run and a test client will issue the standard SSF tests as well as your custom tests.</p> <p>For example:</p> <p>In the same Python file where you defined the <code>SSFApplicationInterface</code>, define a child class of <code>SSFApplicationTestInterface</code> and implement the required methods:</p> <pre><code>from ssf.application import SSFApplicationTestInterface\nlogger = logging.getLogger()\n\n    class MyTestClient(SSFApplicationTestInterface):\n        def begin(self, session, ipaddr: str) -&gt; int:\n            \"\"\"\n            Begin application testing.\n                    session: The Python requests library session (credentials are initialised before calling into application tests).\n                    ipaddr (str): IP address including port (e.g. \"http://0.0.0.0:8100\")\n            Returns:\n                    0 if successful.\n            \"\"\"\n            logger.info(\"MyApp test begin\")\n            return 0\n\n        def subtest(self, session, ipaddr: str, index: int) -&gt; Tuple[bool, str, bool]:\n            \"\"\"\n            Issue test.\n\n            Parameters:\n                    session: The Python requests library session (credentials are initialised before calling into application tests).\n                    ipaddr (str): IP address including port (e.g. \"http://0.0.0.0:8100\")\n                    index (int): Subtest index, starting at zero after 'begin' and incrementing with each call to subtest.\n            Returns:\n                    tuple ((bool, str, bool)):\n                        True if test passed,\n                        A human-readable description of the result (for logging),\n                        True to continue running tests.\n            \"\"\"\n            max_iter = 9\n            test_inputs = [1,2,3,4,5,6,7,8,9,10]\n            logger.debug(\n                f\"MyApp test index={index} out of {max_iter}\"\n            )\n            test_input = test_inputs[index]\n            url = f\"{ipaddr}/tested_endpoint/\"\n            params = {\"x\": f\"{test_input}\"}\n            response = session.post(url, params=params, headers={\"accept\": \"application/json\"}, timeout=5\n                    )\n\n            def eval_result(response):\n                if response.status_code == 200:\n                    return (True, \"Test passed\")\n                else:\n                    return (False, \"Test failed\")\n\n            status, message = eval_result(response)\n            if index &gt;= max_iter:\n                # stop testing\n                return (status, message, False)\n            else:\n                # continue testing\n                return (status, message, True)\n\n\n        def end(self, session, ipaddr: str) -&gt; int:\n            \"\"\"\n            End application testing.\n                    session: The Python requests library session (credentials are initialised before calling into application tests).\n                    ipaddr (str): IP address including port (e.g. \"http://0.0.0.0:8100\")\n            Returns:\n                    0 if successful.\n            \"\"\"\n            logger.info(\"MyApp test ends\")\n            return 0\n\n\n\n    def create_ssf_application_test_instance(ssf_config: SSFConfig) -&gt; SSFApplicationTestInterface:\n        logger.info(\"Create a test instance\")\n        return MyTestClient()\n</code></pre> <p>The method <code>subtest</code> will run in a loop as long as the last value of the output tuple is <code>True</code>. For each iteration, the input <code>index</code> is incremented. Additional checks can be written in the <code>begin</code> and <code>end</code> methods. Note that you also need to define the builder <code>create_ssf_application_test_instance</code> to enable SSF to get the instance. SSFConfig object passed to the test instance factory captures as a copy both the current ssf config and run-time arguments in a single structure and is provided as additional context for the test.</p>"},{"location":"advanced/#check-the-available-ipus","title":"Check the available IPUs","text":"<p>SSF provides a few utilities that you can use when implementing <code>SSFApplicationInterface</code>, You can use <code>get_ipu_count</code> to check how many IPUs are available on the system where your application is executed. <pre><code>from ssf.utils import get_ipu_count\n</code></pre></p>"},{"location":"advanced/#building-an-ssf-image","title":"Building an SSF image","text":"<p>SSF can self package:</p> <p><pre><code>gc-ssf package --package-tag ssf\n</code></pre> The diagram below shows what happens when this command is run:</p> <p></p> <p>The resulting SSF image can be run as an interactive Bash session:</p> <pre><code>gc-docker -- --rm -it --entrypoint bash ssf:latest\n</code></pre> <p>Or it can be used to start an application dynamically by passing options with the SSF_OPTIONS environment variable. The following example shows how the SSF container might be used for rapid deployment of an application:</p> <pre><code>gc-docker -- --rm -d  --env SSF_OPTIONS='--config git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml init build run' ssf:latest\n</code></pre>"},{"location":"advanced/#building-the-wheel-from-sources","title":"Building the wheel from sources","text":"<p>Build the wheel:</p> <pre><code>pip install build\npython -m build\n</code></pre>"},{"location":"advanced/#installing-the-built-wheel","title":"Installing the built wheel","text":"<p>Then install the wheel:</p> <pre><code>python3 -m venv .ssfenv\n. .ssfenv/bin/activate\npip install dist/ssf*.whl\n</code></pre>"},{"location":"advanced/#running-the-cli-from-python","title":"Running the CLI from Python","text":"<p>You can run the SSF CLI from Python. For example:</p> <pre><code>from ssf import cli as ssf_cli\n\nssf_cli.run([\"--config\", \"examples/simple/ssf_config.yaml\", \"init\", \"build\", \"run\"])\n</code></pre>"},{"location":"all_options/","title":"CLI Options","text":""},{"location":"all_options/#general-options","title":"General options:","text":"<ul> <li><code>-a</code> {fastapi,grpc}, <code>--api</code> {fastapi,grpc}                         Which API to generate (default: fastapi)  </li> <li><code>--add-ssh-key</code> ADD_SSH_KEY                         Add an SSH key (for example for a remote repo).                         Provide the key in an environment variable and specify the environment variable name with this argument.                         Multiple keys can be added if necessary. Keys are added before any other commands are processed. (default: None)  </li> <li><code>--modify-config</code> MODIFY_CONFIG                         Add new SSF config fields, or override existing SSF config fields.                         Values will be set as string literal if the field is new, or must otherwise evaluate to the correct type for an existing field.                         Syntax:  \"&lt;field&gt;=&lt;value&gt;;&lt;field&gt;=&lt;value&gt;;...;\". Use \"field[&lt;idx&gt;]=....\" for list entries.                         Example: \"application.trace=False;endpoints[0].id=my_modified_endpoint\"                          (default: None)  </li> <li><code>--file-log-level</code> {DEBUG,INFO,WARNING,ERROR,CRITICAL}                         Set file log level. (default: DEBUG)  </li> <li><code>--stdout-log-level</code> {DEBUG,INFO,WARNING,ERROR,CRITICAL}                         Set stdout log level. (default: INFO)  </li> </ul>"},{"location":"all_options/#runtime-gc-ssf-run-options","title":"Runtime (gc-ssf run) options:","text":"<ul> <li><code>--host</code> HOST           Address to bind to (serve from) (default: 0.0.0.0)  </li> <li><code>-p</code> PORT, <code>--port</code> PORT  Port to bind to (serve from) (default: 8100)  </li> <li><code>-ra</code> REPLICATE_APPLICATION, <code>--replicate-application</code> REPLICATE_APPLICATION                         Number of application instances (default: 1)  </li> <li><code>-k</code> KEY, <code>--key</code> KEY     Secure the API with an API key. (default: None)  </li> <li><code>--watchdog-request-threshold</code> WATCHDOG_REQUEST_THRESHOLD                         Set threshold value in seconds for request duration.                         If exceeded the watchdog will restart the application instance.                         Value set to 0 (default) disables the request duration watchdog. (default: 0)  </li> <li><code>--watchdog-request-average</code> WATCHDOG_REQUEST_AVERAGE                         Set number of last requests included in calculating average watchdog request duration. (default: 3)  </li> <li><code>--watchdog-ready-period</code> WATCHDOG_READY_PERIOD                         Set the time period without a request after which the application instance's watchdog callback function                         will be polled to check that the application is still ready to receive the next request when it arrives.                         If the callback function does not return RESULT_OK then the application instance will be restarted.                         Value set to 0 disables the ready watchdog. (default: 5)  </li> <li><code>--batching-timeout</code> BATCHING_TIMEOUT                         Set how many seconds the server will wait to accumulate samples when batching is enabled. (default: 1)  </li> <li><code>--max-allowed-restarts</code> MAX_ALLOWED_RESTARTS                         Number of time a replica can fails successively on restart before going to an irrecoverable error state (default: 2)  </li> <li><code>--stop-on-error</code>       By default, an application will continue to be served even if in an irrecoverable error state.                         The health probes (<code>health/live</code>, <code>health/ready</code>) can be used to detect this occurence.                         Set this option if you prefer the application to stop and exit immediately on error. (default: False)  </li> <li><code>--prometheus-disabled</code>                         Disable Prometheus client along with SSF server runtime metrics. (default: False)  </li> <li><code>--prometheus-buckets</code> PROMETHEUS_BUCKETS [PROMETHEUS_BUCKETS ...]                         Prometheus buckets to be used with latency and duration metrics. (default: [0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 7.5, 10, 30, 60])  </li> <li><code>--prometheus-endpoint</code> PROMETHEUS_ENDPOINT                         Address of Prometheus metrics endpoint. (default: /metrics)  </li> <li><code>--prometheus-port</code> PROMETHEUS_PORT                         If prometheus-port is is not specified then the Prometheus metrics will share an HTTP server with the service.                         If prometheus-port is specified then two separate HTTP servers will run - one for Prometheus metrics and one for the service. (default: )  </li> </ul>"},{"location":"all_options/#container-options-package-and-publish","title":"Container options (package and publish):","text":"<ul> <li><code>--package-baseimage</code> PACKAGE_BASEIMAGE                         Override default baseimage when packaging.                         The default baseimage is taken from the application config (application.package.docker.baseimage),                         or set to graphcore/pytorch:3.3.0-ubuntu-20.04-20230703. If PACKAGE_BASEIMAGE is specified then it overrides the default baseimage. (default: None)  </li> <li><code>--package-name</code> PACKAGE_NAME                         Override default bundle name when packaging or publishing. (default: None)  </li> <li><code>--package-tag</code> PACKAGE_TAG                         Override default image tag when packaging or publishing.                          Format: <code>--package-tag</code>  user/repo:tag (default: None)  </li> <li><code>--docker-username</code> DOCKER_USERNAME                         Username for login, if login to a docker repository is required when publishing.                         You can login to your docker server before running SSF if preferred, in which case this argument can be skipped.                         If login is required, both username and password must be specified, server is optional.                          (default: None)  </li> <li><code>--docker-password</code> DOCKER_PASSWORD                         Password for login, if login to a docker repository is required when publishing.                         You can login to your docker server before running SSF if preferred, in which case this argument can be skipped.                         If login is required, both username and password must be specified, server is optional.                          (default: None)  </li> <li><code>--container-server</code> CONTAINER_SERVER                         Server for login, if login to a container repository is required when publishing.                         You can login to your container server before running SSF if preferred, in which case this argument can be skipped.                         If login is required, both username and password must be specified, server is optional. (default: None)  </li> </ul>"},{"location":"all_options/#deployment-gc-ssf-deploy-options","title":"Deployment (gc-ssf deploy) options:","text":"<ul> <li><code>--deploy-platform</code> {Paperspace,Gcore}                         The target platform for deployment.                         Gcore deployments start or update a deployment at the specified remote target address using a simple bash boot script and ssh.                         Paperspace deployments create a deployment spec and use the Gradient API to run or update it. (default: Gcore)  </li> <li><code>--deploy-name</code> DEPLOY_NAME                         The deployment name (defaults to application ID if not specified). (default: None)  </li> <li><code>--deploy-package</code>      The default is to deploy an SSF container and dynamically build and run the application from within the SSF container.                         Use this option to instead deploy the application's pre-packaged and published container. (default: False)  </li> <li><code>--deploy-custom-args</code> DEPLOY_CUSTOM_ARGS                         Add additional custom SSF arguments to the deployment SSF CLI invocation.                         The specified argument string will be appended to the default SSF_OPTIONS environment variable that is constructed to pass SSF arguments to the remote target image. (default: None)  </li> <li><code>--deploy-gcore-target-username</code> DEPLOY_GCORE_TARGET_USERNAME                         Gcore: The target username with which to launch the deployment. (default: None)  </li> <li><code>--deploy-gcore-target-address</code> DEPLOY_GCORE_TARGET_ADDRESS                         Gcore: The target address with which to launch the deployment. (default: None)  </li> <li><code>--deploy-paperspace-registry</code> DEPLOY_PAPERSPACE_REGISTRY                         Paperspace: The containerRegistry entry when auto generating the deployment specification for deployment. (default: Graphcore Cloud Solutions Dev R-O)  </li> <li><code>--deploy-paperspace-project-id</code> DEPLOY_PAPERSPACE_PROJECT_ID                         Paperspace: The deployment platform project ID. (default: None)  </li> <li><code>--deploy-paperspace-cluster-id</code> DEPLOY_PAPERSPACE_CLUSTER_ID                         Paperspace: The deployment platform cluster ID. (default: clehbtvty)  </li> <li><code>--deploy-paperspace-api-key</code> DEPLOY_PAPERSPACE_API_KEY                         Paperspace: Name of the environment variable where your token is stored (do not write your token directly here). (default: None)  </li> <li><code>--deploy-paperspace-replicas</code> DEPLOY_PAPERSPACE_REPLICAS                         Paperspace: Number of deployment instances (containers) to start. (default: 1)  </li> <li><code>--deploy-paperspace-spec-file</code> DEPLOY_PAPERSPACE_SPEC_FILE                         Paperspace: The deployment specification will be generated automatically if one is required for the platform.                         It can be overridden with this argument. (default: None)  </li> </ul>"},{"location":"all_options/#test-gc-ssf-test-options","title":"Test (gc-ssf test) options:","text":"<ul> <li><code>--test-skip-stop</code>      Don't stop the application container after running 'test'. (default: False)  </li> <li><code>--test-skip-start</code>     Don't start the application container before running 'test' (assume it is already running). (default: False)  </li> </ul>"},{"location":"all_options/#fastapi-api-options","title":"FastAPI API options:","text":"<ul> <li><code>-rs</code> FASTAPI_REPLICATE_SERVER, <code>--fastapi-replicate-server</code> FASTAPI_REPLICATE_SERVER                         Number of server instances (default: 1)  </li> </ul>"},{"location":"all_options/#grpc-api-options","title":"gRPC API options:","text":"<ul> <li><code>--grpc-max-connections</code> GRPC_MAX_CONNECTIONS                         Maximal number of simultaneous connections to gRPC server. (default: 10)  </li> </ul>"},{"location":"config_detail/","title":"Config Detail","text":""},{"location":"config_detail/#ssf-config","title":"SSF Config","text":"<p>The SSF Config is a YAML format file. A detailed description of all the supported YAML fields is provided below. Required fields are flagged with 'Y'.  </p> <p>For a quick overview of the SSF Config file and how it works with the application interface, see model format.  </p> Field Required Example Description <code>ssf_version</code> Y 1.0.0 The version of SSF for which this config was written and tested <code>application</code> Y Application information - see following section application: <code>..id</code> Y my_app A unique identifier without spaces or special characters <code>..name</code> Y My application The application name in human-readable format <code>..desc</code> Y This is my application A description of the application in human-readable format <code>..version</code> Y 1.0 The version number for this application <code>..module</code> Y my_application.py The Python module that provides the SSF application interface <code>..license_name</code> N CreativeML Open RAIL++-M License License type/name for the application (model or API) <code>..license_url</code> N https://my.co/my_app/LICENSE URL to the license for the application (model or API) <code>..terms_of_service</code> N https://my.co/my_app/TERMS URL to terms of service for the application (model or API) <code>..ipus</code> N 4 Minimum number of required IPUs (can be zero) <code>..max_batch_size</code> N 1 Maximum batch size supported ; see batching <code>..startup_timeout</code> N 60 When testing, maximum time in seconds to wait for the application to be ready <code>..artifacts</code> N [\"weights.onnx\", \"exe_cache/*/\"] List of 'globs' for files that are built when <code>build</code> is issued.These are the files removed when <code>init</code> is issued <code>..trace</code> N True Enable endpoint logging <code>..syspaths</code> N [\"../my_model_src\"] List of directories used to extend the Python sys.path (module search path) <code>..dependencies</code> N Dependencies - see following section application:dependencies: <code>..python</code> N requirements.txt Comma-separated list of Python libraries or a requirements file <code>..poplar</code> N [\"3.2.0\", \"3.3.0\"] List of Poplar SDK versions that are compatible with the application <code>..package</code> N Packaging - see following section application:package: <code>..inclusions</code> N [\"weights.onnx\", \"exe_cache/*/\"] List of 'globs' for application-specific files to include when packaging <code>..exclusions</code> N [\"intermediates/*/\"] List of 'globs' for application-specific files to exclude when packaging <code>..name</code> N \"my_app_bundle_v{{application.version}}.tar.gz\" Filename for package tarball; if not specified then defaults to <code>&lt;application.name&gt;.&lt;application.version&gt;.tar.gz</code> <code>..tag</code> N \"my-repo/{{application.id}}:{{application.version}}\" Tag for package image; if not specified then defaults to <code>&lt;application.name&gt;:&lt;application.version&gt;</code> <code>..docker</code> N Docker packaging - see following section application:package:docker: <code>..baseimage</code> N \"graphcore/pytorch:3.3.0-ubuntu-20.04\" Use this specific base image when packaging the image (else the current SSF default will be used) <code>..run</code> N |-2\u00a0\u00a0RUN apt-get install -y \\\u00a0\u00a0libsm6 libxext6 libboost-all-dev \\\u00a0\u00a0libjpeg-dev libtiff-dev libpng-dev Custom Dockerfile lines <code>endpoints</code> Y List of end-points - see following section endpoints: <code>..id</code> Y \"MyAPI\" An identifier without spaces or special characters. See end-points <code>..version</code> N 2 The version number for this end-point  (defaults to 1) <code>..desc</code> N \"This is my API end-point\" A description of the end-point in human-readable format <code>..http_param_format</code> N query How to pass input data. More details in the section Requests data format. <code>..custom</code> N \"my_custom_endpoint.py\" Use this Python file as the FastAPI endpoint implementation <code>..inputs</code> Y List of inputs - see following section endpoints:inputs: <code>..id</code> Y x A unique identifier without spaces or special characters <code>..type</code> Y Integer One of the SSF defined types <code>..desc</code> N \"An integer value\" A description of the input in human-readable format <code>..example</code> N 10 An example value for this input <code>..outputs</code> Y List of outputs - see following section endpoints:outputs: <code>..id</code> Y x_times_1000 A unique identifier without spaces or special characters <code>..type</code> Y Integer One of the SSF defined types <code>..desc</code> N \"Input value x times 1000\" A description of the input in human-readable format"},{"location":"config_detail/#notes","title":"Notes","text":""},{"location":"config_detail/#fastapi-end-points","title":"FastAPI End-points","text":"<p>SSF will code-generate the server endpoint for the inputs/outputs and map it through the user application <code>request</code> function provided in the <code>SSFApplicationInterface</code> instance.  The endpoint code is automatically generated as:</p> <p><code>/v&lt;version&gt;/&lt;id&gt;</code></p> <p>For example, if <code>version</code> is <code>1</code> and <code>id</code> is <code>my_endpoint</code>, then it will generate:</p> <p><code>/v1/my_endpoint</code></p> <p>The combination of <code>version</code> and <code>id</code> must be unique for the application.  </p> <p>You can override the SSF code-generated endpoint and use your own module by specifying an endpoint file to import with the <code>custom</code> option.</p> <p>Parameter examples will be provided in the FastAPI generated OpenAPI definition and Swagger UI. Parameter examples are supported only when using the FastAPI runtime and only for the basic types (<code>Integer</code>, <code>String</code>, <code>Float</code>, <code>Boolean</code>) and the list variants (<code>ListInteger</code>, <code>ListString</code>, <code>ListFloat</code>, <code>ListBoolean</code>). The provided example values must be convertible to the parameter's declared type. Examples for List type parameters must be a comma-separated list of values; for example, given a parameter with type <code>ListInteger</code>: <code>example: 1,2,3</code>. </p>"},{"location":"config_detail/#requests-data-format","title":"Requests data format","text":"<p>SSF will declare inputs to be delivered in the request body parameters (json) by default. The exceptions are:</p> <ul> <li>If <code>http_param_format: query</code> is declared in the SSF config for the end point, or</li> <li>If the end-point includes a custom input type (such as TempFile).</li> </ul> <p>In these cases SFF will declare inputs to be delivered query parameters. You might use <code>http_param_format: query</code> in your SSF config to force query-in-request-params. Note that using query parameters for long inputs is not recommended, this can cause unwanted behaviour due to URL size https://stackoverflow.com/questions/417142/what-is-the-maximum-length-of-a-url-in-different-browsers/417184#417184.</p>"},{"location":"config_detail/#ssf-types","title":"SSF types","text":""},{"location":"config_detail/#basic-types","title":"Basic types","text":"<p>The following basic types are supported:</p> ssf_config.yml expected Python type (in app) <code>String</code> <code>str</code> <code>Integer</code> <code>int</code> <code>Float</code> <code>float</code> <code>Boolean</code> <code>bool</code>"},{"location":"config_detail/#list-types","title":"List types:","text":"<p>List types can also be used as a single input/output:</p> ssf_config.yml expected Python type (in app) <code>ListString</code> <code>List[str]</code> <code>ListInteger</code> <code>List[int]</code> <code>ListFloat</code>: <code>List[float]</code> <code>ListBoolean</code> <code>List[bool]</code> <code>ListAny</code><sup>*</sup> <code>list</code> <p><sup>*</sup>Experimental</p>"},{"location":"config_detail/#input-file-handling","title":"Input file handling","text":"<p>The following file handling types are supported as input:</p> <ul> <li><code>TempFile</code> (input only): This supports upload of file over interface, the file is saved in the server (temporary) and queued to the request as a filename.</li> </ul>"},{"location":"config_detail/#specialised-types","title":"Specialised types","text":"<ul> <li><code>PngImageBytes</code> (output only): This can be used to return a PNG image as content with media_type=\"image/png\".</li> </ul>"},{"location":"config_detail/#self-reference-expansion","title":"Self-reference Expansion","text":"<ul> <li>The SSF config yaml file supports self-reference expansion for string entries; so, for our example, \"{{application.id}}.tar.gz\" would expand to \"simple_test.tar.gz\".</li> </ul>"},{"location":"config_detail/#modifying-the-config-with-the-cli","title":"Modifying the config with the CLI","text":"<ul> <li>The SSF config can be modified at run-time using the <code>--modify-config</code> CLI argument. Modifications are applied immediately after the yaml is loaded and before self-reference expansion. New fields are added as string type. Modifications to existing fields must match the existing type.</li> </ul>"},{"location":"config_detail/#primary-application-context","title":"Primary application context","text":"<ul> <li>The SSF config folder can be considered the primary application folder or context. All files, modules and directories should be specified relative to the SSF config folder. The current working directory will be set to the application module folder before SSF calls any of the application entry points (<code>build</code> or <code>request</code> etc.).</li> </ul>"},{"location":"config_detail/#python-module-search-paths","title":"Python module search paths","text":"<ul> <li>SSF adds the SSF config folder and application module folder (if it is different) to the Python module search path before the application module is loaded. The SSF config field <code>syspaths</code> can be used to add any additional directories. The search priority order is: <code>syspaths</code> first, in declared order, followed by the application module folder, followed by the SSF config folder last.</li> </ul>"},{"location":"config_detail/#glob-declaration","title":"Glob declaration","text":"<ul> <li>The SSF config settings that take 'globs' (artifacts, inclusions and exclusions) follow the behaviour documented here: glob documentation for Python 3.9. The <code>recursive</code> argument is set to True, so the pattern <code>**</code> can be used and will match any files and zero or more directories.</li> </ul> <p>WARNINGS:</p> <ul> <li>The SSF config setting <code>artifacts</code> supports 'glob' matching of files that will be removed when the <code>init</code> command is issued. This feature is intended to remove only files that are generated by the <code>build</code> command, so that the next <code>build</code> will re-generate these files. SSF does not apply any checks or limits on the set of files matched for removal - take care that only the necessary expected files will be matched.</li> </ul>"},{"location":"config_detail/#default-versions","title":"Default versions","text":"<p>Use <code>gc-ssf --help</code> to find version information such as:</p> <ul> <li>Which SSF config versions are supported</li> <li>The default base image used for packaging</li> <li>The default SSF image used when deploying using a pre-built SSF image</li> </ul> <p>For example:</p> <pre><code>Simple Server Framework 1.1.0\n\nSupports application config ssf_version: 0.0.1 - 1.1.0\nPackage default base image: graphcore/pytorch:3.3.0-ubuntu-20.04-20230703\nDeploy default SSF image: graphcore/simple-server-framework:1.1.0\n</code></pre>"},{"location":"features/","title":"Features","text":""},{"location":"features/#features","title":"Features","text":""},{"location":"features/#running-an-application-from-a-remote-repository","title":"Running an application from a remote repository","text":"<p>The config can specify a remote application with the syntax:</p> <p><code>&lt;REPO&gt;{@BRANCH|@SHA}|&lt;config yaml file&gt;</code></p> <p>Where <code>&lt;REPO&gt;</code> can be specified in standard Git protocol form such as:</p> <ul> <li><code>git@&lt;remote&gt;</code> - use the <code>Git</code> protocol where the repository is being served.</li> <li><code>https://&lt;remote&gt;</code> - use the <code>HTTP</code> protocol where the repository is being served and is public.</li> <li><code>ssh://&lt;user&gt;@&lt;host&gt;</code> - use the <code>SSH</code> protocol where the repository is on a remote server.</li> <li><code>file:///&lt;local path&gt;</code> - use the <code>File</code> protocol where the repository is on the local file system.</li> </ul> <p>If a config yaml file is not specified then the default <code>ssf_config.yaml</code> file (from the repo root) is used.</p> <p>The repo code is freshly cloned when <code>init</code> is issued.</p> <p>Code is pulled to CWD <code>.repo/&lt;repo name&gt;/...</code></p> <p> For example:</p> <p><pre><code>gc-ssf  --config 'https://github.com/graphcore/simple-server-framework|examples/simple/ssf_config.yaml' init build run\n</code></pre> This will clone <code>simple-server-framework</code> to <code>.repo/simple-server-framework/...</code> and then build and run the <code>simple</code> example.</p>"},{"location":"features/#pinning-a-specific-branch-or-version","title":"Pinning a specific branch or version","text":"<p>You can also specify a branch or a commit hash. For instance: <pre><code>gc-ssf  --config 'git@github.com:username/my-repo.git@my-branch|path/to/ssf_config.yaml' init build run\n</code></pre></p> <p>This also works when using <code>deploy</code>. Check out this example for more details.</p>"},{"location":"features/#specifying-a-local-application-git-repository","title":"Specifying a local application git repository","text":"<p>You can specify a local repository during development or for testing (if running SSF locally). For instance: <pre><code>gc-ssf  --config 'file:///my-repo|path/to/ssf_config.yaml' init build run\n</code></pre></p>"},{"location":"features/#register-ssh-keys","title":"Register SSH keys","text":"<p>You can use SSH keys to deploy to a VM. SSH keys can be registered locally without specifying other commands; the key string needs to be stored in an enviroment variable, for example <code>ENV_KEY</code>:</p> <pre><code>gc-ssf --add-ssh-key ENV_KEY\n</code></pre>"},{"location":"features/#optional-api-key","title":"Optional API key","text":"<p>We advise you not to open the generated endpoints publicly, use dedicated services to secure them. SSF provides a minimal security layer, when using the command <code>run</code> you can decide to set a key.</p> <p>Use the <code>--key &lt;KEY&gt;</code> option to set an API key.</p> <p>See <code>--key</code> in options for more details.</p>"},{"location":"features/#replication","title":"Replication","text":"<p>Replication provides a mechanism for scaling the whole application. Replication levels can be used individually or stacked together depending on the required use case.</p>"},{"location":"features/#application-replication","title":"Application replication","text":"<p>Use the <code>--replicate-application &lt;N&gt;</code> option to create multiple application instances within one server instance. There will be <code>&lt;N&gt;</code> concurrent instances of the <code>SSFApplicationInterface</code>. Incoming requests will be put in an internal FIFO queue and therefore will be handled in the order they were received.</p> <p>Choose this mechanism for applications where the average time spent on request handling (on IPUs) is significantly higher than the time spent on receiving the request and preparing the data.</p> <p>See <code>--replicate-application</code> in options for more details.</p>"},{"location":"features/#server-replication-fastapi-only","title":"Server replication (FastAPI only)","text":"<p>Use the <code>--fastapi-replicate-server &lt;K&gt;</code> option to create multiple server instances.</p> <p>See <code>--fastapi-replicate-server</code> in options for more details.</p> <p>NOTE: The value of <code>&lt;K&gt;</code> should not be higher than the number of processor cores on the machine that is used to run the server. Setting this value higher will cause performance degradation.</p> <p>There will be <code>&lt;K&gt;</code> server instances working in <code>&lt;K&gt;</code> separate processes. Incoming requests will be assigned a process by the OS scheduler mechanism. This mechanism will generally choose a process that is waiting on I/O or not consuming CPU resources.</p> <p>Choose server replication if the processor cores are likely to spend more time receiving the request and preparing the data than the amount of time the IPUs spend processing the input.</p>"},{"location":"features/#stacking-replication-mechanism-fastapi-only","title":"Stacking replication mechanism (FastAPI only)","text":"<p>In some cases it may useful to use both these replication mechanisms (dispatcher and server) together. It should be noted that the number of occupied IPUs in a ready state can be calculated using this formula:</p> <p>IPUs = I * K * N</p> <p>where:</p> <ul> <li>I is the number of IPUs used by one application instance</li> <li>K is <code>&lt;K&gt;</code> used as value for <code>--fastapi-replicate-server &lt;K&gt;</code></li> <li>N is <code>&lt;N&gt;</code> used as value for <code>--replicate-application &lt;N&gt;</code></li> </ul> <p>If the required number of IPUs are not available then the server will fail to boot.</p>"},{"location":"features/#batching","title":"Batching","text":"<p>Applications may benefit from being able to process multiple inputs at once. For this purpose <code>max_batch_size</code> may be set in your SSF config and this will instruct the server to accumulate user requests into batches of the defined maximal batch size. When set, applications will receive (through a <code>request</code> api) a list of size <code>J</code> containing &lt;1,<code>max_batch_size</code>&gt; dictionaries structured as defined in the SSF config. In this case the SSF server expects this function to return <code>J</code> dictionaries structured as defined in the SSF config.</p> <p>NOTE: The order of the output results should match the order of the input samples in the batch.</p> <p>A server batching timeout can be set using the <code>--batching-timeout &lt;T&gt;</code> run option. The server will wait a maximum of <code>&lt;T&gt;</code> seconds to accumulate up to <code>max_batch_size</code> samples. After <code>&lt;T&gt;</code> seconds have elapsed after receiving the first sample of the batch, the server will send as many samples as it has accumulated.</p> <p>When <code>max_batch_size</code> is not set a batch size of 1 is assumed.</p> <p>See <code>--batching-timeout</code> in options for more details.</p>"},{"location":"features/#health-probes","title":"Health probes","text":"<p>The SSF server implements <code>health/</code> probes that can be used for higher level monitoring. The three probes available that can be pinged by the GET method are:</p> <ul> <li><code>health/startup</code>:(200:success, other:failure) Succeed as soon as the server has started.</li> <li><code>health/live</code>: (200:success, other:failure) Liveness probe. Succeed as long as your server is alive. Failing liveness means that an irrecoverable error happened and the container should be restarted. Example one: Your application crashed during startup, liveness should then be down. Example 2: Your application has been running for some time and you have set the option <code>--max-allowed-restarts</code> to 5. If your application crashes and keeps crashing on restart, after 5 attempts by the watchdog mechanism you will have exceeded the <code>max-allowed-restarts</code> and liveness will be down.</li> <li><code>health/ready</code>: (200:success, other:failure). Readiness probe. Returns 200 as soon as your application is ready to receive requests. Typically returns 200 when at least one replica is ready.</li> </ul> <p>See <code>--max-allowed-restarts</code> in options for more details.</p>"},{"location":"features/#interaction-with-replicate-application","title":"Interaction with --replicate-application","text":"<ul> <li><code>health/live</code>: This returns Success until at least one replica is permanently stopped (max allowed restarts is reached).</li> <li><code>health/ready</code>: This returns Success while there is at least one live and ready replica.</li> </ul> <p>It is possible for liveness to be down while readiness is still up in the situation where one replica has failed but another is still running.</p>"},{"location":"features/#metrics","title":"Metrics","text":"<p>By default SSF starts a Prometheus client, allowing the collection of runtime metrics. There is a fixed set of metric basenames, including the following:</p> <ul> <li><code>ssf_dispatch_latency</code> - duration of request limited to time spent in application.</li> <li><code>[http/grpc]_request_duration_seconds</code> - duration of HTTP/gRPC requests in seconds (seen by ASGI channel).</li> <li><code>[http/grpc]_request_size_bytes</code> - size of requests in bytes.</li> <li><code>[http/grpc]_response_size_bytes</code> - size of responses in bytes.</li> </ul>"},{"location":"features/#scope","title":"Scope","text":"<p>SSF metrics are exported in separate groups so you can distinguish events that differ by:</p> <ul> <li>SSF endpoint address (name and version)</li> <li>response status codes - 2xx, 3xx, 4xx and so on for FastAPI or error code / OK status for gRPC</li> </ul> <p>The following endpoints are excluded from metrics:</p> <ul> <li>the Prometheus metrics endpoint itself (configurable with SSF <code>run</code> argument <code>--prometheus-endpoint</code>)</li> <li>health checks routes - <code>/startup/</code>, <code>/ready/</code>, <code>/live/</code></li> </ul> <p>See <code>--prometheus-endpoint</code> in options for more details.</p>"},{"location":"features/#command-line-configuration","title":"Command line configuration","text":"<p>The following SSF run arguments can be used for SSF Prometheus configuration:</p> <ul> <li><code>--prometheus-disabled</code> - (default: not present) by default metrics client is started, adding this argument will disable it.</li> <li><code>--prometheus-endpoint</code> - (default: \"/metrics\") URL path on which server will expose the metrics.</li> <li><code>--prometheus-buckets</code> - buckets to be used for all duration metrics (for details see Latencies and buckets).</li> <li><code>--prometheus-port</code> - defines the port on which Prometheus metrics are exposed. When this argument is passed, SSF will start a separate HTTP server running Prometheus client and the metrics will be available on any given address on the chosen port. When this argument is not passed, metrics port depends on the chosen API:</li> <li>for <code>fastapi</code>: the Prometheus client will be served on the same port using the same FastAPI server as the the service. In this case metrics will be accessible on endpoint <code>/metrics</code>. It is possible to change the metrics endpoint using the <code>--prometheus-endpoint</code> argument</li> <li>for <code>gRPC</code>: the port will default to the server port incremented by one i.e. when SSF server runs on port 8200 then metrics will be served on port 8201</li> </ul> <p>See <code>--prometheus-***</code> in options for more details.</p>"},{"location":"features/#latencies-and-buckets","title":"Latencies and buckets","text":"<p>Metrics that represent durations have been implemented as Prometheus <code>histograms</code> which means that the events are counted in configurable buckets. Each duration metric with a name containing &lt;basename&gt; exposes multiple time series:</p> <ul> <li>&lt;basename&gt;_bucket - cumulative counters for the observation buckets. Each bucket is defined by a number that is interpreted as the threshold value of duration in seconds and the bucket counts the requests which have a duration that is equal to, or smaller than, the defined threshold value. When not configured the following buckets are created by default: [ 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 7.5, 10, 30, 60 ]. The last bucket is always <code>+Inf</code>and collects all events.</li> <li>&lt;basename&gt;_sum - the total sum of all durations.</li> <li>&lt;basename&gt;_count - the count of events that have been observed (value-wise identical to bucket <code>+Inf</code>)</li> </ul> <p>As an example of how to use these metrics, to get a graph of average <code>ssf_dispatch_latency</code> you would draw <code>ssf_dispatch_latency_sum</code> / <code>ssf_dispatch_latency_count</code>. This definition is possible because of the Prometheus server support for expressions.</p>"},{"location":"features/#watchdog","title":"Watchdog","text":"<p>The SSF server provides watchdog capabilities to handle application runtime problems by detecting bad states and restarting the application under defined conditions.</p>"},{"location":"features/#runtime-generic-watchdog","title":"Runtime generic watchdog","text":"<p>This is an internal server watchdog which detects if an application's process exists (regardless of the reason) and will restart the process if it has stopped.</p>"},{"location":"features/#request-duration-watchdog","title":"Request duration watchdog","text":"<p>The server can monitor request duration and restart the application if the averaged request duration time exceeds requested threshold. This feature can be set using the following run options:</p> <ul> <li><code>--watchdog-request-threshold &lt;T&gt;</code> float value T sets a threshold in seconds. Default value is 0 which disables the request duration watchdog.</li> <li><code>--watchdog-request-average &lt;A&gt;</code> integer A defines the number of last requests included in calculating the average watchdog request duration.</li> </ul> <p>See <code>--watchdog-request-threshold</code> and <code>--watchdog-request-average</code> in options for more details.</p>"},{"location":"features/#application-watchdog","title":"Application watchdog","text":"<p>Applications can expose a custom watchdog which is being monitored by the SSF server. For details see <code>watchdog</code> in application's interface details. This will be called periodically by the server while no requests are being issued.</p> <p>See option <code>--watchdog-ready-period</code> in options for more details. </p>"},{"location":"features/#apis","title":"APIs","text":"<p>SSF supports serving inference through HTTP/S endpoints (FastAPI) and gRPC endpoints (gRPC Python). The endpoint can be chosen using argument <code>--api</code> with value <code>fastapi</code> or <code>grpc</code>. By default SSF uses <code>--api fastapi</code> to start HTTP/S endpoint. If <code>--api</code> is used to override this, then you must set <code>--api</code> for all issued commands (build, run, package etc).</p> <p>See <code>--api</code> in options for more details.</p>"},{"location":"grpc/","title":"gRPC","text":""},{"location":"grpc/#grpc-support","title":"gRPC support","text":""},{"location":"grpc/#enabling-grpc-in-ssf","title":"Enabling gRPC in SSF","text":"<p>To serve endpoints with the gRPC framework in SSF add <code>--api grpc</code> to SSF command line arguments. For example:</p> <pre><code>gc-ssf --config example/simple/ssf_config_grpc.yaml build run --api grpc\n</code></pre> <p>Support for a gRPC framework has been implemented using the grpcio Python module. SSF servers supports reflection so the gRPC framework can be discovered using clients that support reflection. The gRPC runtime is based on Predict Protocol - Version 2 proposed by KServe. Predict Protocol support is limited to the data types that are supported in SSF.</p>"},{"location":"grpc/#configuration","title":"Configuration","text":"<ul> <li><code>--grpc-max-connections</code> [default: 10] - number of possible simultaneous connections.</li> </ul>"},{"location":"grpc/#compatibility-between-fastapi-and-grpc-api","title":"Compatibility between FastAPI and gRPC api","text":""},{"location":"grpc/#any-and-listany","title":"<code>Any</code> and <code>ListAny</code>","text":"<p>The gRPC API features that are available match the FastAPI features, with the sole exception of the <code>Any</code> type, which is only available with FastAPI. If the SSF config YAML file contains <code>Any</code> or <code>ListAny</code> types then a gRPC enabled SSF will fail to boot. For gRPC API supporting applications, users must replace <code>Any</code> and <code>ListAny</code> types with the best matching strong type.</p>"},{"location":"grpc/#server-replication","title":"Server replication","text":"<p>Direct control over the number of receiver threads running is not possible when using gRPC. Instead, the user can specify the maximum number of parallel client connections using the <code>--grpc-max-connections</code> command line argument when calling gc-ssf. The default number of gRPC workers is set to 10.</p>"},{"location":"grpc/#testing","title":"Testing","text":"<p>Most of the SSF examples contain tests that are designed to communicate using a REST style. The SSF testing engine can reuse those tests with a gRPC framework by using a proxy session which translates REST requests to gRPC requests. For the tests in the <code>tests</code> directory, proxy sessions can be used for tests that are build on top of the <code>model.TestModel</code>class. In order to run the gRPC test execute <code>self.test_model(API_GRPC)</code>.</p>"},{"location":"grpc/#sending-a-request-with-predict-protocol-version-2-python","title":"Sending a request with Predict Protocol - Version 2 (Python)","text":"<p>gRPC clients can be implemented with many different frameworks and programming languages and describing such implementations is out of scope of this documentation. SSF starts a server that is reflection capable so the protocol itself can be discovered by the client. Nevertheless there are some SSF specific concepts that have to be obeyed in order to successfully communicate with the SSF gRPC API.</p> <p>The quick guide below shows an example of how to properly construct a request using Python:</p> <ol> <li>Create an empty <code>request</code>:</li> </ol> <pre><code>request = proto_predict_v2.ModelInferRequest()\n</code></pre> <ol> <li>Specify details for the endpoints in the <code>parameters</code> container of the request using <code>version</code> and <code>endpoint</code> keys. The values must match the values defined in the SSF application config YAML file.</li> </ol> <pre><code>request.parameters[\"version\"].string_param = \"1\"\nrequest.parameters[\"endpoint\"].string_param = \"TestEndpoint\"\n</code></pre> <ol> <li>Add inputs according to the application config. <code>name</code> for the input must match the one defined in the SSF application config YAML file.</li> </ol> <pre><code>inputs = []\n\n# adding float values\nvalues = [1.3, 4.5, 5.0, 3.4]\ninputs.append(self.proto_predict_v2.ModelInferRequest().InferInputTensor())\ninputs[-1].name = \"name_of_the_input__float\"\ninputs[-1].shape.append(len(values))\ninputs[-1].contents.fp64_contents.extend(values)\n\n# adding integer values\nvalues = [1, 4, 5, 3]\ninputs.append(self.proto_predict_v2.ModelInferRequest().InferInputTensor())\ninputs[-1].name = \"name_of_the_input__int\"\ninputs[-1].shape.append(len(values))\ninputs[-1].contents.int_contents.extend(values)\n\n# adding boolean values\nvalues = [True, False, True, False, False]\ninputs.append(self.proto_predict_v2.ModelInferRequest().InferInputTensor())\ninputs[-1].name = \"name_of_the_input__boolean\"\ninputs[-1].shape.append(len(values))\ninputs[-1].contents.bool_contents.extend(values)\n\n# adding string values\nvalues = [\"test string 1\", \"test string 2\"]\ninputs.append(self.proto_predict_v2.ModelInferRequest().InferInputTensor())\ninputs[-1].name = \"name_of_the_input__string\"\ninputs[-1].shape.append(len(values))\nvalues_encoded = [bytes(elt, \"UTF-8\") for elt in values]\ninputs[-1].contents.bytes_contents.extend(values_encoded)\n\n# adding file input\n# for file client has to additionally specify file name with extension in `file_name` parameter\nwith open(input_image, \"rb\") as fp:\n    inputs.append(self.proto_predict_v2.ModelInferRequest().InferInputTensor())\n    inputs[-1].name = \"name_of_the_input__file\"\n    inputs[-1].shape.append(1)\n    inputs[-1].parameters[\"file_name\"].string_param = \"test_file.jpg\"\n    inputs[-1].contents.bytes_contents.append(fp.read())\n\nrequest.inputs.extend(inputs)\n</code></pre> <ol> <li>Send the request (how to perform a server initialization is described in the selected framework guide i.e. for Python gRPC in offical documentation)</li> </ol>"},{"location":"grpc/#receiving-a-response-with-predict-protocol-version-2-python","title":"Receiving a response with Predict Protocol - Version 2 (Python)","text":"<p>When receiving a request the client may follow these steps:</p> <ol> <li>Check if the response contains member <code>outputs</code>.</li> </ol> <pre><code>if hasattr(response, \"outputs\"):\n    # process outputs\nelse:\n    pass\n</code></pre> <ol> <li>For each output get the <code>datatype</code> attribute and process it accordingly:</li> </ol> <pre><code># integers are stored in int_contents member\nif output.datatype == \"INT32\":\n    ret_val_decoded = [elt for elt in output.contents.int_contents]\n\n# floats are stored in fp64_contents member\nelif output.datatype == \"FP64\":\n    ret_val_decoded = [elt for elt in output.contents.fp64_contents]\n\n# booleans are stored in bool_contents member\nelif output.datatype == \"BOOL\":\n    ret_val_decoded = [elt for elt in output.contents.bool_contents]\n\n# strings are stored in bytes_contents member\nelif output.datatype == \"BYTE_STRING\":\n    ret_val = output.contents.bytes_contents\n    while len(ret_val):\n        # string values have to be decoded\n        ret_val_decoded.append(ret_val.pop(0).decode())\n\n# byte arrays are stored in bytes_contents member\nelif output.datatype == \"BYTES\":\n    ret_val = output.contents.bytes_contents\n    while len(ret_val):\n        # pop instead of list comprehension to free the memory on the fly\n        ret_val_decoded.append(ret_val.pop(0))\n</code></pre>"},{"location":"grpc/#testing-grpc","title":"Testing gRPC","text":"<p>To test your gRPC, any client that supports reflection can be used. A quick way to test is to use <code>grpcui</code> which starts a client directly from DockerHub. When initializing the client, make sure to match the port that was set when booting SSF:</p> <pre><code>docker run --init --rm -p 8080:8080 --network=host fullstorydev/grpcui -max-msg-sz 10063522 -plaintext 0.0.0.0:50051\n</code></pre>"},{"location":"history/","title":"History","text":""},{"location":"history/#v10","title":"v1.0","text":""},{"location":"history/#features","title":"Features","text":"<ul> <li>Core features and workflow <code>init</code>, <code>build</code>, <code>run</code>, <code>package</code>, <code>test</code>, <code>publish</code>, <code>deploy</code></li> <li>FastAPI runtime server</li> <li>Built-in example models: MNIST, Stable Diffusion</li> </ul>"},{"location":"history/#v11","title":"v1.1","text":""},{"location":"history/#changes","title":"Changes","text":"<ul> <li>Bug fixes</li> <li>Documentation improvements</li> </ul>"},{"location":"history/#new-features","title":"New Features","text":"<ul> <li>gRPC runtime server (See gRPC)</li> <li>Prometheus metrics (See metrics)</li> <li>Result codes are defined (See result codes)</li> <li>Example values for input fields can be declared (FastAPI) (See examples)</li> <li>The SSF Config and CLI arguments are now available for the user's application (See application interface)</li> <li>Run-time modification/override of SSF Config via CLI (See general options)</li> <li>Built-in example models: Added Whisper fine-tuning</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python version &gt;= 3.7.</li> <li>A Poplar SDK and appropriate framework must be installed and enabled to <code>build</code> or <code>run</code> an application that uses IPU.</li> <li>Docker version &gt;= 23.0 must be installed, locally to <code>package</code> and <code>publish</code>, and on the deployment target to <code>deploy</code>.</li> </ul>"},{"location":"installation/#installing-ssf-as-a-cli-from-the-repo","title":"Installing SSF as a CLI from the repo","text":"<p>Using Pip:</p> <pre><code>pip install git+https://git@github.com/graphcore/simple-server-framework.git\n</code></pre> <p>Now you will be able to run <code>gc-ssf</code>.</p>"},{"location":"installation/#running-ssf-from-source","title":"Running SSF from source","text":"<p>To run SSF from source you need to follow these steps.</p>"},{"location":"installation/#clone-the-repo","title":"Clone the repo","text":"<p>First you will need to clone the repo: <pre><code>git clone https://github.com/graphcore/simple-server-framework.git\n</code></pre></p>"},{"location":"installation/#create-a-virtual-environment","title":"Create a virtual environment","text":"<p>Then create a virtual environment: <pre><code>python3 -m venv .ssfenv\n</code></pre></p>"},{"location":"installation/#activate-the-virtual-environment","title":"Activate the virtual environment","text":"<p>You can then activate the virtual environment: <pre><code>. .ssfenv/bin/activate\npip install -e simple-server-framework/\n</code></pre></p>"},{"location":"installation/#for-ipu-users","title":"For IPU users","text":"<p>If you want to build applications for IPUs, you also need to install the Poplar SDK from the Graphcore download portal.</p>"},{"location":"installation/#using-ssf-from-the-public-docker-container","title":"Using SSF from the public Docker container.","text":"<p>SSF is available as a container. It can be deployed on a remote target as a server (see this example. But can also be used to develop locally:</p> <pre><code>docker pull docker.io/graphcore/simple-server-framework\n</code></pre> <p>To use it as an interactive bash session: <pre><code>docker run --rm -it --network host --entrypoint bash graphcore/simple-server-framework:latest\n</code></pre></p> <p>Alternatively, you can also execute a single SSF command by passing all arguments to the container via the environment variable SSF_OPTIONS: <pre><code>docker run --rm -d --network host --env SSF_OPTIONS='--config git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml init build run' --name simple-server-framework graphcore/simple-server-framework:latest\n</code></pre></p> <p>For IPU users: If your local system has IPUs and you want your container to access them, you may want to use <code>gc-docker</code>. Alternatively, just pass these additional arguments to <code>docker run</code> (<code>IPUOF_VIPU_API_HOST</code> and <code>IPUOF_VIPU_API_PARTITION_ID</code> should be configured properly on your system): <pre><code>--ulimit memlock=-1:-1 --net=host --cap-add=IPC_LOCK --device=/dev/infiniband/ -e IPUOF_VIPU_API_HOST=$IPUOF_VIPU_API_HOST -e IPUOF_VIPU_API_PARTITION_ID=$IPUOF_VIPU_API_PARTITION_ID-8 --ipc=host\n</code></pre></p>"},{"location":"model_format/","title":"Model Format","text":""},{"location":"model_format/#model-format","title":"Model format","text":"<p>SSF is framework agnostic and does not enforce a specific model serialization format. The only restriction is that your ML model must be callable from Python. We describe how to adapt any ML model so it can be used in SSF below.</p> <p>For detailed documentation of all the SSF Config fields, see config detail.</p>"},{"location":"model_format/#create-an-application-interface","title":"Create an application interface","text":"<p>Create a Python file local to your application code. In that file, create an application specific concrete class inheriting from <code>SSFApplicationInterface</code>:</p> <pre><code>from ssf.application import SSFApplicationInterface, SSFConfig\nclass MyApplication(SSFApplicationInterface):\n  ...\n</code></pre> <p>Implement the required methods:</p> <pre><code>class MyApplication(SSFApplicationInterface):\n    def __init__(self, ssf_config : SSFConfig):\n        pass\n\n    def build(self) -&gt; int:\n        \"\"\"\n        Build required dependencies.\n        This could be building custom-ops, binary executables, model-preprocessing, and so on.\n        Consider running the model to capture a PopEF file as an optimisation.\n        This is called when `gc-ssf build` is issued.\n\n        Returns:\n                0 (RESULT_OK) if successful.\n        \"\"\"\n\n    def startup(self) -&gt; int:\n        \"\"\"\n        One-time startup for the application instance.\n        Consider priming the application instance by issuing a dummy request.\n        This is called during `gc-ssf run` before requests are started.\n\n        Returns:\n                0 (RESULT_OK) if successful.\n        \"\"\"\n\n    def request(\n        self, params: Union[dict, list], meta: Union[dict, list]\n    ) -&gt; Union[dict, list]:\n        \"\"\"\n        Request for inference.\n        This is called by the dispatcher for each queued request while `gc-ssf run` is running.\n\n        Parameters:\n                params (dict | list): Input parameters as a dictionary. Dictionary fields must match inputs declared in the SSF config.\n                meta (dict | list): Metadata fields such as `endpoint_id`, `endpoint_version` and `endpoint_index` to support multiple or versioned endpoints.\n        Returns:\n                Output parameters as a dictionary or list of dictionaries. Dictionary fields must match outputs declared in the SSF config.\n        Note:\n                When `max_batch_size` in the SSF config is greater than 1 then input parameters will be a list of dictionaries and the respective return values must be a list of dictionaries.\n        \"\"\"\n\n    def shutdown(self) -&gt; int:\n        \"\"\"\n        One-time shutdown for the application instance.\n        This is called during `gc-ssf run` when requests are stopped.\n\n        Returns:\n                0 (RESULT_OK) if successful.\n        \"\"\"\n\n    def watchdog(self) -&gt; int:\n        \"\"\"\n        Called after a period of request inactivity to check the application instance is still ready to receive requests.\n        If the application instance has an unrecoverable failure then its watchdog can return failure which will cause the server to restart the application instance.\n        If failures can not be detected, or they are handled internally, the default implementation can be used.\n\n        Returns:\n               0 (RESULT_OK) if successful.\n        \"\"\"\n</code></pre> <p>(Optional) You can declare your application's class <code>__init__</code> method with or without the named argument <code>ssf_config</code>. If used, then the SSF config will be passed in as a copy of the SSF internal run-time configuration. This may be useful to the application if it needs to adapt at run-time based on SSF config details. The following fields are provided:</p> <ul> <li><code>ssf_config.config_dict</code> : The SSF config (YAML) as a dictionary, after expansion (see NOTES). You may add application-specific custom fields and sections in the SSF config and reference these in your application interface using <code>ssf_config.config_dict</code>.  See also, CLI argument <code>--modify-config</code>.</li> <li><code>ssf_config.args</code> : The SSF CLI arguments for this SSF invocation, as an argparse Namespace object in <code>ssf_confing.args</code>.</li> <li><code>ssf_config.unknown_args</code> : The SSF CLI arguments for this SSF invocation that are unknown. The SSF CLI is tolerant to unknown arguments so it is possible to pass through arguments to your application.</li> </ul> <p>Warnings:</p> <ul> <li>The <code>ssf_config</code> object contains other fields that are implementation dependent and subject to change between versions of SSF.</li> </ul> <p>(Optional) You can also declare a custom factory method named <code>create_ssf_application_instance</code> that will return your <code>SSFApplicationInterface</code> instance. For example, if you need to pass custom arguments to the  init method.</p> <pre><code>def create_ssf_application_instance() -&gt; SSFApplicationInterface`\n  return MyApplication()\n</code></pre> <p>Or, if you want to pass through the SSF config,</p> <pre><code>def create_ssf_application_instance(ssf_config) -&gt; SSFApplicationInterface`\n  return MyApplication(ssf_config)\n</code></pre> <p>See <code>examples/simple/my_application.py</code> for more details.</p>"},{"location":"model_format/#optional-return-code","title":"(Optional) Return code","text":"<p>When you implement <code>SSFApplicationInterface</code> methods, you can use <code>ssf.results</code> to set a return code for the <code>build</code> methods  . <pre><code>from ssf.results import *\n</code></pre></p> <p>See result codes.</p>"},{"location":"model_format/#create-an-ssf-config","title":"Create an SSF Config","text":"<p>Create an SSF config <code>ssf_config.yaml</code> file next to your application code (where you created the application interface module).</p> <p>See <code>examples/simple/ssf_config.yaml</code> for more details.</p> <p>Your SSF config file should define the version of SSF for which this config was written and tested. For example:</p> <pre><code>ssf_version: 1.0.0\n</code></pre> <p>It should also include top-level application details, for example:</p> <pre><code>application:\n  id: simple_test\n  name: Test API\n  desc: A very simple test API.\n  version: 1.0\n  module: my_application.py\n  ipus: 0\n</code></pre> <p>Where:</p> <ul> <li><code>id</code>: (<code>str</code>) Unique identifier for the application (no spaces)</li> <li><code>name</code>: (<code>str</code>) Human readable one-liner title</li> <li><code>desc</code>: (<code>str</code>) Human readable expanded description</li> <li><code>version</code>: (<code>str</code>) Application-specific versioning</li> <li><code>module</code>: (<code>str</code>) The name of your application module in which <code>SSFApplicationInterface</code> implementation can be found</li> <li><code>ipus</code> : <code>(int)</code> The number of IPUs required to run one instance of the application; can be zero; if not specified then SSF assumes 1 IPU is required</li> </ul> <p>You should also add a list of endpoints. Multiple endpoints can be declared.</p> <p>These may have the same (if only version is changing) or different IDs. Calls to the application request interface include metadata such as the endpoint ID, version and list index plus the replica index of the application instance.</p> <p>For example:</p> <pre><code>endpoints:\n\n  - id: Test1\n    version: 1\n    desc: Test1\n</code></pre> <p>Where:</p> <ul> <li><code>id</code>: (<code>str</code>) Endpoint unique id (no spaces)</li> <li><code>version</code>: (<code>str</code>) Endpoint version</li> <li><code>desc</code>: (<code>str</code>) Human readable description</li> </ul> <pre><code>    inputs:\n      - id: x:\n        type: Integer\n        desc: A value\n        example: 10\n\n\n    outputs:\n      - id: requests:\n        type: Integer\n        desc: Count of requests.\n\n      - id: x_times_1000:\n        type: Integer\n        desc: Input value x times 1000.\n</code></pre> <p>Where:</p> <ul> <li><code>id</code>:  Parameter id (name)</li> <li><code>type</code>: Type (one of the SSF defined types)</li> <li><code>desc</code>: Human readable one-liner description</li> <li><code>example</code> : Example value for this parameter</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#quickstart","title":"Quickstart","text":"<p>Install gc-ssf:</p> <pre><code>pip install git+https://git@github.com/graphcore/simple-server-framework.git\n</code></pre> <p>Run a demonstration:</p> <pre><code>gc-ssf  --config 'https://github.com/graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml' init build run\n</code></pre> <p>This should start with lines that are similar to:</p> <pre><code>2023-10-19 12:28:49,635 414627     INFO      &gt; Repo https://github.com/graphcore/simple-server-framework.git (cli.py:632)\n2023-10-19 12:28:49,635 414627     INFO      &gt; Repo dir .repo (cli.py:633)\n2023-10-19 12:28:49,635 414627     INFO      &gt; Repo name simple-server-framework (cli.py:634)\n2023-10-19 12:28:49,635 414627     INFO      &gt; Config .repo/simple-server-framework/examples/simple/ssf_config.yaml (cli.py:635)\n2023-10-19 12:28:49,635 414627     INFO      &gt; Config file examples/simple/ssf_config.yaml (cli.py:636)\n2023-10-19 12:28:49,635 414627     INFO      &gt; Checkout None (cli.py:637)\n2023-10-19 12:28:49,635 414627     INFO      &gt; Cloning repo (cli.py:648)\n</code></pre> <p>This shows SSF cloning the target application repository (<code>https://github.com/graphcore/simple-server-framework.git</code>) to your local <code>.repo</code> directory. For this quickstart demonstration, we are runing an example from the SSF repository itself.  </p> <p>After cloning the repository, SSF will <code>build</code> and <code>run</code> the example application (<code>examples/simple/ssf_config.yaml</code>)  </p> <p>Look for lines later in the output that are similar to:</p> <pre><code>2023-10-19 12:28:53,013 414627     INFO      &gt; ==== Run ==== (run.py:23)\n2023-10-19 12:28:53,014 414627     INFO      &gt; Starting fastapi runtime with .repo/simple-server-framework/examples/simple/ssf_config.yaml (run.py:41)\n2023-10-19 12:28:53,019 414627     INFO      &gt; Address 10.3.49.180:8100 (run.py:46)\n</code></pre> <p>This tells you the address and port on which the application end-points have been started.  </p> <p>The trace should end with lines that are similar to:</p> <pre><code>2023-10-19 12:28:53,742 414687     INFO      instance=&lt;simple-test.MyApplication object at 0x7f4b20f29460&gt; (dispatcher.py:188)\n2023-10-19 12:28:53,742 414687     INFO      &gt; [0] Running app from /nethome/demo/workspace/ssf/.repo/simple-server-framework/examples/simple (dispatcher.py:189)\n2023-10-19 12:28:53,742 414687     INFO      &gt; [0] Startup user application instance (dispatcher.py:193)\n2023-10-19 12:28:53,742 414687     INFO      MyApp startup (my_application.py:20)\n2023-10-19 12:28:54,453 414627     INFO      Dispatcher ready (dispatcher.py:542)\n2023-10-19 12:28:58,748 414687     INFO      [0] Dispatcher polling application replica watchdog (dispatcher.py:242)\n</code></pre> <p>This shows that the application has started and the dispatcher object through which calls (requests) to the application are made is ready. You will see repeated polls of the application watchdog while the end-point is idle; this is the SSF built-in watchdog feature. See watchdog for further details.</p> <p>Use a browser to open the endpoint docs with the format <code>http://&lt;address&gt;/docs</code>, for example <code>http://10.3.49.180:8100/docs</code>.</p> <p>Tip: If you are using Visual Studio Code with a remote connection to your development host then you can use the Port forwarding feature to add the served port (<code>8100</code> in this example) and browse the endpoint directly in your VSC client using the built-in simple browser.</p>"},{"location":"quickstart/#next-steps","title":"Next steps","text":"<p>Read installation for more detailed options for installing SSF and its pre-requisites.</p> <p>Read the walkthrough for a complete example of the full workflow for developing your own application, including packaging and deployment.</p> <p>Read model format for an overview of the SSF model application interface.</p> <p>Read usage for an overview of the SSF command line interface.</p> <p>Read features and advanced use for more complex use cases and examples.</p>"},{"location":"result_codes/","title":"Result codes","text":"Result Code Description RESULT_OK 0 Success/OK. RESULT_ARGUMENT_ERROR 1 Misformed or unexpected argument. RESULT_FAIL 2 Generic 'failure' code. RESULT_INTERNAL_ERROR 3 Unexpected issue within SSF. RESULT_FRAMEWORK_RESOURCE_ERROR 4 Issue with framework generated resources. RESULT_SSH_ERROR 5 Issue with an SSH key or host. RESULT_DOCKER_BUILD_ERROR 6 Issue with Docker build. RESULT_DOCKER_SERVER_ERROR 7 Issue with Docker server login or push. RESULT_DOCKER_STATUS_ERROR 8 Issue with Docker status. RESULT_NETWORK_ERROR 9 Issue with networking status. RESULT_INSTALLATION_ERROR 10 Issue installing a dependency. RESULT_DEPLOYMENT_ERROR 11 Issue deploying an application. RESULT_NOT_IMPLEMENTED_ERROR 12 Missing or incomplete feature. RESULT_GIT_REPO_ERROR 13 Issue with accessing git repository. RESULT_APPLICATION_ERROR 32 Issue within the user application. RESULT_APPLICATION_TEST_ERROR 33 Failure returned from the user application test. RESULT_APPLICATION_CONFIG_ERROR 34 Issue within the user application config file. RESULT_APPLICATION_MODULE_ERROR 35 Issue loading the user application module or creating an application instance. RESULT_PACKAGING_ERROR 36 Issue packaging the user application. RESULT_UVICORN_ERROR 128 Issue within the FastAPI Uvicorn runner. RESULT_GRPC_SERVER_ERROR 152 gRPC framework exception RESULT_GRPC_SSF_ERROR 153 Issue within gRPC logic of SSF RESULT_GRPC_REQUEST_ERROR 154 Malformed / not correct request RESULT_GRPC_APP_CONFIG_ERROR 155 Application configuration problem RESULT_PAPERSPACE_DEPLOYMENT_ERROR 176 Paperspace deployment specific issue. RESULT_GCORE_DEPLOYMENT_ERROR 177 Gcore deployment specific issue. RESULT_UNMET_REQUIREMENT 255 The runner environment does not meet the minimum application requirement."},{"location":"usage/","title":"CLI Usage","text":""},{"location":"usage/#cli-usage","title":"CLI usage","text":"<p>The SSF command line interface consists of the following main commands and a <code>--config</code> path.</p> <ul> <li>init</li> <li>build</li> <li>run</li> <li>package</li> <li>publish</li> <li>deploy</li> <li>test</li> </ul> <p>These commands can be used with various options.</p> <p>The format is: <pre><code>gc-ssf --config &lt;ssf-config-path&gt; COMMAND [options]\n</code></pre> Multiple commands can be used within the same line: <pre><code>gc-ssf --config &lt;ssf-config-path&gt; COMMAND1 COMMAND2 [options]\n</code></pre></p> <p>(Note: If <code>--config</code> is not defined, SSF will look for an <code>ssf_config.yaml</code> file in the current directory.)</p> <p>All SSF commands will return a result code. RESULT_OK (0) is expected for succesful completion.  </p> <p>If multiple commands are issued, each command is actioned in turn while they each return RESULT_OK. If a command fails to return RESULT_OK, then SSF will return immediately and subsequents steps will be skipped.</p> <p>For a complete list of result codes, see result codes.</p> <p>By default, SSF will print INFO level log to the terminal (stdout) and DEBUG level log to its log file <code>ssf.log</code>. The log file, <code>ssf.log</code>, can contain useful additional information if SSF returns with an error or throws an exception. The log levels can be modified; see <code>--file-log-level</code> and <code>--stdout-log-level</code> in options for more details.</p> <p>SSF is tolerant to unknown arguments and commands. SSF will log these as warnings.</p>"},{"location":"usage/#ssf-init","title":"SSF init","text":"<p><code>init</code> is designed to set up a clean environment before you build. This will:</p> <ul> <li>Remove endpoint artifacts generated by a previous <code>build</code></li> <li>Remove custom <code>artifacts</code> (if any) specified in ssf_config.yaml</li> <li>Clone a repo if using a remote model repository</li> </ul> <p>For example: <pre><code># Example 1: remove all generated endpoint files related to ssf_config.yaml\ngc-ssf --config examples/simple/ssf_config.yaml init\n\n\n# Example 2: remove all generated endpoint files related to ssf_config.yaml\n# also clone a fresh copy of the remote repo git@github.com:graphcore/simple-server-framework.git\ngc-ssf --config 'git@github.com:graphcore/simple-server-framework.git|examples/simple/ssf_config.yaml' init\n</code></pre></p>"},{"location":"usage/#ssf-build","title":"SSF build","text":"<p>This shows how to issue <code>build</code> for an example. This step will generate the API endpoint files. It will also instantiate the application and run the <code>build</code> method. You can use this to write custom preparation steps to run offline, for example  compilation, weights download, cache generation, and so on.</p> <p><pre><code>gc-ssf --config examples/simple/ssf_config.yaml build\n</code></pre> Example output: <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml build\n2023-03-28 16:40:20,893 644580     INFO      ==== Build ==== (build.py:15)\n2023-03-28 16:40:20,893 644580     INFO      &gt; Generate_endpoints (build.py:17)\n2023-03-28 16:40:20,898 644580     INFO      &gt; Load application (build.py:20)\n2023-03-28 16:40:20,898 644580     INFO      Creating application (application.py:95)\n2023-03-28 16:40:20,898 644580     INFO      Checking application dependencies (application.py:97)\n2023-03-28 16:40:20,898 644580     INFO      Loading simple_test application from /home/examples/simple/my_application.py with module id simple_test (application.py:103)\n2023-03-28 16:40:20,898 644580     INFO      loading module /home/examples/simple/my_application.py with module name simple_test (utils.py:110)\n2023-03-28 16:40:20,898 644580     INFO      Create MyApplication instance (my_application.py:34)\n2023-03-28 16:40:20,898 644580     INFO      &gt; Build application (build.py:23)\n2023-03-28 16:40:20,898 644580     INFO      Changed directory to /home/examples/simple (utils.py:123)\n2023-03-28 16:40:20,898 644580     INFO      MyApp build (my_application.py:14)\n2023-03-28 16:40:20,898 644580     INFO      Returned directory to /home (utils.py:127)\n</code></pre></p> <p>The endpoint files are auto-generated in the current working directory:</p> <pre><code>ssf_simple_test_endpoint_0_fastapi.py\nssf_simple_test_endpoint_1_fastapi.py\n</code></pre> <p>NOTE: Use <code>init</code> to remove build artifacts.</p>"},{"location":"usage/#ssf-run","title":"SSF run","text":"<p>Start running the server. It is assumed the endpoints already exist (=&gt; issue <code>build</code> first.)</p> <p>This shows how to issue <code>run</code> for an example.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml run\n</code></pre> <p>Example output:</p> <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml run\n2023-03-28 16:41:29,813 644749     INFO      ==== Run ==== (run.py:17)\n2023-03-28 16:41:29,813 644749     INFO      &gt; Starting fastapi runtime with examples/simple/ssf_config.yaml (run.py:28)\n2023-03-28 16:41:29,813 644749     INFO      &gt; Running Uvicorn (ssf_run.py:24)\n2023-03-28 16:41:29,989 644749     INFO      &gt; Running FastAPI server (server.py:27)\n2023-03-28 16:41:29,995 644749     INFO      &gt; Test API : A very simple test API (server.py:38)\n2023-03-28 16:41:29,996 644749     INFO      &gt; Creating FastAPI applications (server.py:43)\n2023-03-28 16:41:29,996 644749     INFO      &gt; Creating FastAPI instance (server.py:50)\n2023-03-28 16:41:29,997 644749     INFO      &gt; Loading endpoints for simple_test (server.py:79)\n2023-03-28 16:41:29,997 644749     INFO      &gt; Loading simple_test endpoint from /home/ssf_simple_test_endpoint_0_fastapi.py with module id simple_test_endpoint_0 (server.py:85)\n2023-03-28 16:41:29,997 644749     INFO      loading module /home/ssf_simple_test_endpoint_0_fastapi.py with module name simple_test_endpoint_0 (utils.py:110)\n2023-03-28 16:41:29,998 644749     INFO      Loaded /home/ssf_simple_test_endpoint_0_fastapi.py for simple_test endpoint (ssf_simple_test_endpoint_0_fastapi.py:33)\n2023-03-28 16:41:30,000 644749     INFO      &gt; Loading simple_test endpoint from /home/ssf_simple_test_endpoint_1_fastapi.py with module id simple_test_endpoint_1 (server.py:85)\n2023-03-28 16:41:30,000 644749     INFO      loading module /home/ssf_simple_test_endpoint_1_fastapi.py with module name simple_test_endpoint_1 (utils.py:110)\n2023-03-28 16:41:30,002 644749     INFO      Loaded /home/ssf_simple_test_endpoint_1_fastapi.py for simple_test endpoint (ssf_simple_test_endpoint_1_fastapi.py:33)\n2023-03-28 16:41:30,004 644749     WARNING   API key has not been specified, endpoints are not secured. (server.py:94)\n2023-03-28 16:41:30,005 644749     INFO      Started server process [644749] (server.py:74)\n2023-03-28 16:41:30,005 644749     INFO      Waiting for application startup. (on.py:48)\n2023-03-28 16:41:30,005 644749     INFO      &gt; Startup (server.py:106)\n2023-03-28 16:41:30,011 644815     INFO      Dispatcher started for simple_test [644749-&gt;644815] (dispatcher.py:59)\n2023-03-28 16:41:30,011 644815     INFO      &gt; Getting user application instance (dispatcher.py:64)\n2023-03-28 16:41:30,011 644815     INFO      Creating application (application.py:95)\n2023-03-28 16:41:30,011 644815     INFO      Checking application dependencies (application.py:97)\n2023-03-28 16:41:30,011 644815     INFO      Loading simple_test application from /home/examples/simple/my_application.py with module id simple_test (application.py:103)\n2023-03-28 16:41:30,011 644815     INFO      loading module /home/examples/simple/my_application.py with module name simple_test (utils.py:110)\n2023-03-28 16:41:30,012 644815     INFO      Create MyApplication instance (my_application.py:34)\n2023-03-28 16:41:30,012 644815     INFO      instance=&lt;simple_test.MyApplication object at 0x7fc0503ab250&gt; (dispatcher.py:66)\n2023-03-28 16:41:30,012 644815     INFO      &gt; Initialising user application instance (dispatcher.py:69)\n2023-03-28 16:41:30,012 644815     INFO      MyApp initialise (my_application.py:18)\n2023-03-28 16:41:31,012 644749     INFO      Application startup complete. (on.py:62)\n2023-03-28 16:41:31,013 644749     INFO      Uvicorn running on http://0.0.0.0:8100 (Press CTRL+C to quit) (server.py:217)\n</code></pre> <p>It is valid to combine build and run in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml build run\n</code></pre>"},{"location":"usage/#ssf-package","title":"SSF package","text":"<p>This shows how to issue <code>package</code> for an example. It is assumed the endpoints already exist (=&gt; issue <code>build</code> first.)</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml package\n</code></pre> <p>This will pull resources into a local directory (<code>.package</code>) and build a docker image with name <code>&lt;application_id&gt;:latest</code></p> <p>Example output:</p> <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml package\n2023-03-28 21:03:52,071 1307287    INFO      ==== Package ==== (package.py:15)\n2023-03-28 21:03:52,071 1307287    INFO      &gt; Packaging simple_test to /home/.package (package.py:30)\n2023-03-28 21:03:52,072 1307287    INFO      &gt; Package SSF from /home/ssf (package.py:70)\n2023-03-28 21:03:52,077 1307287    INFO      &gt; Package Application from /home/examples/simple (package.py:86)\n2023-03-28 21:03:52,077 1307287    INFO      &gt; Package Endpoint files (package.py:90)\n2023-03-28 21:03:52,078 1307287    INFO      &gt; Generate docker image (package.py:126)\n2023-03-28 21:03:52,114 1307287    INFO      [Docker image build] Sending build context to Docker daemon  103.9kB (utils.py:73)\n2023-03-28 21:03:52,198 1307287    INFO      [Docker image build] Step 1/14 : FROM graphcore/pytorch:3.1.0-ubuntu-20.\n[...]\n2023-03-28 21:03:52,226 1307287    INFO      [Docker image build]  ---&gt; Using cache (utils.py:73)\n2023-03-28 21:03:52,226 1307287    INFO      [Docker image build]  ---&gt; 1a39476a9bb4 (utils.py:73)\n2023-03-28 21:03:52,226 1307287    INFO      [Docker image build] Step 14/14 : CMD cd src &amp;&amp; ./run.sh (utils.py:73)\n2023-03-28 21:03:52,227 1307287    INFO      [Docker image build]  ---&gt; Using cache (utils.py:73)\n2023-03-28 21:03:52,227 1307287    INFO      [Docker image build]  ---&gt; ed9945bd6e3a (utils.py:73)\n2023-03-28 21:03:52,228 1307287    INFO      [Docker image build] Successfully built ed9945bd6e3a (utils.py:73)\n2023-03-28 21:03:52,230 1307287    INFO      [Docker image build] Successfully tagged simple_test:latest (utils.py:73)\n2023-03-28 21:03:52,237 1307287    INFO      &gt; Run: 'docker run --rm -d --network host --name simple_test simple_test:latest' (package.py:137)\n2023-03-28 21:03:52,237 1307287    INFO      &gt; Logs: 'docker logs simple_test' (package.py:138)\n2023-03-28 21:03:52,237 1307287    INFO      &gt; Stop: 'docker stop simple_test' (package.py:139)\n</code></pre> <p>It is valid to combine build and package in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml build package\n</code></pre>"},{"location":"usage/#ssf-publish","title":"SSF publish","text":"<p>This shows how to issue 'publish' for an example.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml publish\n</code></pre> <p>This will push the most recent packaged docker image to a docker server (default Docker Hub).</p> <p>This assumes the docker server is already logged in, but if a docker username and password are provided, then these will be used to login before pushing. A specific server may also be specified if required using <code>--container-server</code>.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml --docker-username &lt;username&gt; --docker-password &lt;password&gt; publish\n</code></pre> <p>Example output:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml publish\n2023-04-11 17:41:36,382 1273566    INFO      &gt; Config examples/simple/ssf_config.yaml (cli.py:334)\n2023-04-11 17:41:36,387 1273566    INFO      &gt; ==== Publish ==== (publish.py:15)\n2023-04-11 17:41:37,212 1273566    INFO      &gt; Docker push user/myapp:simple_test-1.0-latest to DockerHub (publish.py:43)\n2023-04-11 17:41:37,252 1273566    INFO      [Push user/myapp:simple_test-1.0-latest] The push refers to repository [docker.io/user/myapp] (utils.py:193)\n2023-04-11 17:41:37,509 1273566    INFO      [Push user/myapp:simple_test-1.0-latest] 0f277cce0197: Preparing (utils.py:193)\n[...]\n2023-04-11 17:41:40,249 1273566    INFO      [Push user/myapp:simple_test-1.0-latest] simple_test-1.0-latest: digest:\nsha256:cb...0d6 size: 5996 (utils.py:193)\n</code></pre> <p>It is assumed the package already exist (=&gt; issue 'package' first.)</p> <p>It is valid to combine package and publish in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml package publish\n</code></pre>"},{"location":"usage/#ssf-deploy","title":"SSF deploy","text":"<p>This shows how to issue 'deploy' for an example. <pre><code>gc-ssf --config examples/simple/ssf_config.yaml [options] deploy\n</code></pre></p> <p>It is assumed the image already exists on Docker hub, two possibilities:</p> <ul> <li>You have packaged it yourself and used <code>publish</code> first, then use the option <code>--deploy-package</code> (see example 1)</li> <li>You use the public pre-build SSF image (see example 2)</li> </ul> <p>It is valid to combine publish and deploy in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml [options] publish deploy\n</code></pre>"},{"location":"usage/#deployment-to-gcore","title":"Deployment to Gcore","text":"<p>For Gcore the deployment commands are passed using SSH. So the required options will be:</p> <ul> <li><code>--deploy-platform</code> (Gcore)</li> <li><code>--deploy-gcore-target-address</code>: The Gcore VM IP address to SSH</li> <li><code>--deploy-gcore-target-username</code>: The Gcore VM username to SSH (by default VMs use <code>ubuntu</code>)</li> </ul> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml  --deploy-platform Gcore --deploy-gcore-target-address &lt;ipaddr&gt; --deploy-gcore-target-username &lt;username&gt; deploy\n</code></pre> <p>For example: <pre><code>gc-ssf deploy --config ssf_config.yaml --deploy-platform Gcore --port 8100 --deploy-gcore-target-address 123.456.789.0 --deploy-gcore-target-username ubuntu --docker-username dockerUser --docker-password my-docker-token --add-ssh-key KEY_ENV_VARIABLE --deploy-package\n</code></pre></p> <p>This will deploy the most recently published image to the target platform (Gcore).</p> <p>The config application ID is used for the deployment name unless <code>--deploy-name</code> is used to override it.</p> <p>This will create a new deployment or update an existing deployment with the same deployment name if one already exists.</p> <p>The target server must have already been created.</p> <p>Use <code>--add-ssh-key</code> to add an SSH key via environment variable if required.</p>"},{"location":"usage/#deployment-to-paperspace","title":"Deployment to Paperspace","text":"<p>For Paperspace the deployment is made using the <code>Gradient</code> API. So the required options will be:</p> <ul> <li><code>--deploy-platform</code> (Paperspace)</li> <li><code>--deployment-paperspace-api-key</code> : The Paperspace API key</li> <li><code>--deploy-paperspace-project-id</code> : The Paperspace project ID</li> <li><code>--deployment-paperspace-cluster-id</code> : The Paperspace cluster ID</li> <li><code>--deploy-paperspace-registry</code> : The Paperspace container registry</li> </ul> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml --deploy-platform Paperspace --deploy-paperspace-project-id &lt;projectId&gt; --deployment-paperspace-cluster-id &lt;clusterId&gt; --deploy-paperspace-registry &lt;registry&gt; --deployment-paperspace-api-key &lt;apiKey&gt; deploy\n</code></pre> <p>For example: <pre><code>gc-ssf deploy --config examples/simple/ssf_config.yaml --deploy-platform Paperspace --deploy-paperspace-project-id p01234567890 --deployment-paperspace-cluster-id c01234567 --deploy-paperspace-registry \"Graphcore Cloud Solutions Dev R-O\" --deploy-paperspace-api-key PAPERSPACE_API_KEY --package-tag graphcore/cloudsolutions-dev:mnist_api-1.0 --deploy-package\n</code></pre></p> <p>This will deploy the most recently published image, <code>graphcore/cloudsolutions-dev:mnist_api-1.0</code>, as a Paperspace deployment where the project ID is <code>p01234567890</code>, the cluster ID is <code>c01234567</code>, and the API key has been pre-set in environment variable <code>PAPERSPACE_API_KEY</code>.</p> <p>The config application ID is used for the deployment name unless <code>--deploy-name</code> is used to override it.</p> <p>This will create a new deployment or update an existing deployment if one already exists.</p> <p>The project and API key must have already been created and a container registry must have already been configured (see <code>--deploy-paperspace-registry</code>).</p>"},{"location":"usage/#deployment-arguments","title":"Deployment arguments","text":"<p>See <code>gc-ssf --help</code> for other <code>--deploy-</code> arguments.</p> <p>Some SSF CLI arguments, for example <code>--port</code>, <code>--key</code>, <code>--replication-dispatcher</code> and <code>--fastapi-replicate-server</code>, are passed to the remote deployment using the <code>SSF_OPTIONS</code> environment variable. The <code>ssf.log</code> can be used to check arguments passed to the remote deployment.</p> <p>The SSF CLI argument <code>--deploy-custom-args</code> can be used to append additional arguments to the <code>SSF_OPTIONS</code> environment variable. This might be useful to pass additional arguments or override existing arguments.</p>"},{"location":"usage/#ssf-test","title":"SSF test","text":"<p>This shows how to issue 'test' for an example.</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml test\n</code></pre> <p>This will start and test the current packaged Docker image (run <code>gc-ssf package</code> first.)\\</p> <p>2 types of test are issued:</p> <ul> <li>Built-in SSF tests (always run): Testing that the server runs normally (for instance accessing root endpoint)</li> <li>Custom tests (optional): Users can define their own tests to run with this command, see the section \"Create a test interface for your application\".</li> </ul> <p>If the current system can not satisfy the application dependency (for example the required Poplar version), then the test will be skipped and a warning will be logged.</p> <p>If IPUs are required then remember to set 'ipus' in the SSF config.</p> <p>Example output:</p> <pre><code>$ gc-ssf --config examples/simple/ssf_config.yaml test\n2023-05-04 10:33:04,800 1578140    INFO      &gt; Config examples/simple/ssf_config.yaml (cli.py:404)\n2023-05-04 10:33:04,805 1578140    INFO      &gt; ==== Test ==== (test.py:12)\n2023-05-04 10:33:04,805 1578140    INFO      &gt; Start simple-test user/repo:simple-test-1.0-latest (test.py:263)\n2023-05-04 10:33:04,871 1578140    INFO      SSF_OPTIONS=-p 8100 --key test_key (test.py:65)\n2023-05-04 10:33:05,118 1578140    INFO      &gt; Wait simple-test (test.py:276)\n2023-05-04 10:33:10,202 1578140    INFO      &gt; Subtest Check root endpoint (test.py:279)\n2023-05-04 10:33:10,223 1578140    INFO      &gt; Subtest Check security logout (test.py:286)\n2023-05-04 10:33:10,243 1578140    INFO      &gt; Subtest Check security forbidden (test.py:293)\n2023-05-04 10:33:10,260 1578140    INFO      &gt; Subtest Check security accepted (test.py:300)\n2023-05-04 10:33:10,277 1578140    INFO      OK 4 KO 0 (test.py:307)\n2023-05-04 10:33:10,324 1578140    INFO      &gt; Stop simple-test (test.py:314)\n2023-05-04 10:33:20,559 1578140    INFO      &gt; Remove simple-test (test.py:316)\n</code></pre> <p>It is assumed the package already exist (=&gt; issue 'package' first.)</p> <p>It is valid to combine package and test in one step:</p> <pre><code>gc-ssf --config examples/simple/ssf_config.yaml package test\n</code></pre> <p>If the test passes, then <code>gc-ssf test</code> will return <code>RESULT_OK</code> (0).</p> <p>If the test is skipped (for example, due to configuration) then <code>gc-ssf test</code> will return <code>RESULT_UNMET_REQUIREMENT</code> (255).</p> <p>If the test fails, then a <code>SSFExceptionApplicationTestError</code> exception will be thrown. Example: <pre><code>SSFExceptionApplicationTestError: simple-test failed testing OK:7 KO:1\n</code></pre></p>"},{"location":"walkthrough/","title":"Walkthrough","text":""},{"location":"walkthrough/#walkthrough","title":"Walkthrough","text":"<p>This walkthrough will show how to serve an application using SSF and deploy it on Gcore to use IPUs. As a prerequisite we need to follow the installation instructions to install and enable the Poplar SDK with Poptorch in the environment.</p>"},{"location":"walkthrough/#select-a-model","title":"Select a model","text":"<p>For this example we deploy a pre-trained question answering model from Huggingface. Distilbert-base-cased-distilled-squad will do the trick \ud83e\udd17 The model itself can be imported from the optimum-graphcore library as an inference pipeline:</p> <pre><code>from optimum.graphcore import pipeline\n\nquestion_answerer = pipeline(\n    \"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n)\n</code></pre> <p>Note that the input is a dictionary containing <code>question</code> and <code>context</code> strings. The output is also a dictionary containing an <code>answer</code> string, the <code>score</code>, and the <code>start</code> and <code>end</code> positions of the answer in the <code>context</code> string.</p>"},{"location":"walkthrough/#implement-the-application-interface","title":"Implement the application interface","text":"<p>To interface our model with SSF we need to implement the application interface  <code>SSFApplicationInterface</code>. The following file <code>my_app.py</code> shows the code needed for this:</p> <pre><code>from optimum.graphcore import pipeline\nimport logging\nfrom ssf.application import SSFApplicationInterface\nfrom ssf.utils import get_ipu_count\nfrom ssf.results import RESULT_OK, RESULT_APPLICATION_ERROR\n\nlogger = logging.getLogger()\n\nclass MyApplication(SSFApplicationInterface):\n    def __init__(self):\n        self.question_answerer: pipeline = None\n        self.dummy_inputs_dict = {\n            \"question\": \"What is your name?\",\n            \"context\": \"My name is Rob.\",\n        }\n\n\n    def build(self) -&gt; int:\n        if get_ipu_count() &gt;= 2:\n            logger.info(\"Compiling model...\")\n            build_pipeline = pipeline(\n                \"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n            )\n            build_pipeline(self.dummy_inputs_dict)\n        else:\n            logger.info(\n                \"IPU requirements not met on this device, skipping compilation.\"\n            )\n        return RESULT_OK\n\n\n    def startup(self) -&gt; int:\n        logger.info(\"App started\")\n        self.question_answerer = pipeline(\n            \"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n        )\n        self.question_answerer(self.dummy_inputs_dict)\n        return RESULT_OK\n\n\n    def request(self, params: dict, meta: dict) -&gt; dict:\n        result = self.question_answerer(params)\n        return result\n\n\n    def shutdown(self) -&gt; int:\n        return RESULT_OK\n\n\n    def watchdog(self) -&gt; int:\n        result = self.question_answerer(self.dummy_inputs_dict)\n        return RESULT_OK if result[\"answer\"] == \"Rob\" else RESULT_APPLICATION_ERROR\n</code></pre> <p>Now let's explain this step-by-step.</p> <p>SSF will serve an instance of <code>MyApplication</code>. To implement the interface we need to define the 5 methods <code>build</code>, <code>startup</code>, <code>request</code>, <code>shutdown</code> and <code>watchdog</code>:</p> <ul> <li>In the <code>__init__</code> method we define a placeholder for the <code>question_answerer</code>. We also define a dummy input dictionary that will be used to test the pipeline.</li> </ul> <pre><code>class MyApplication(SSFApplicationInterface):\n    def __init__(self):\n        self.question_answerer: pipeline = None\n        self.dummy_inputs_dict = {\n            \"question\": \"What is your name?\",\n            \"context\": \"My name is Rob.\",\n        }\n</code></pre> <ul> <li>The <code>build</code> method is called when issuing gc-ssf build. It should contain any preliminary steps that we want to happen offline, before running the server. Since we are using IPUs, we can compile the model in advance to save time at server startup. To do that, we should call the <code>pipeline</code> object at least once (the first call triggers compilation). The IPU compilation generates a cache <code>exe_cache/</code>, we explain later how to package this cache alongside the server. HuggingFace libraries will also download and cache model weights. We may not have access to IPUs to run the <code>build</code> step outside of our deployment environment - we can check this by using the utility function <code>get_ipu_count</code>. If we don't have access to IPUs it will skip compilation which will then be triggered by <code>startup</code> when deployed. Note: we use <code>return RESULT_OK</code> from ssf return codes, this is equivalent to <code>return 0</code></li> </ul> <pre><code>    def build(self) -&gt; int:\n        if get_ipu_count() &gt;= 2:\n            logger.info(\"Compiling model...\")\n            build_pipeline = pipeline(\n                \"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n            )\n            build_pipeline(self.dummy_inputs_dict)\n        else:\n            logger.info(\n                \"IPU requirements not met on this device, skipping compilation.\"\n            )\n        return RESULT_OK\n</code></pre> <ul> <li>The <code>startup</code> method is called every time the server starts (when issuing gc-ssf run) so it can contain any warmup code we need. We instantiate and call the pipeline with dummy inputs: if the compilation cache exists, this first call will have the effect of attaching the model to available IPUs. If not, it will compile it first. Since the lifespan of <code>self.question_answerer</code> is the same as <code>MyApplication</code>, the model will stay attached to the IPUs as long as the <code>MyApplication</code> instance is alive.</li> </ul> <pre><code>    def startup(self) -&gt; int:\n        logger.info(\"App started\")\n        self.question_answerer = pipeline(\n            \"question-answering\", model=\"distilbert-base-cased-distilled-squad\"\n        )\n        self.question_answerer(self.dummy_inputs_dict)\n        return RESULT_OK\n</code></pre> <ul> <li>The <code>request</code> method is the function executed by our API call. It is important to understand what will be in the dictionaries <code>params</code>(the inputs) and <code>return</code>(the output) as SSF will use it later to generate the API.</li> </ul> <pre><code>    def request(self, params: dict, meta: dict) -&gt; dict:\n        result = self.question_answerer(params)\n        return result\n</code></pre> <ul> <li>Any resource freeing can be carried out in the <code>shutdown</code> method. We have left it empty:</li> </ul> <pre><code>    def shutdown(self) -&gt; int:\n        return RESULT_OK\n</code></pre> <ul> <li>Finally, <code>watchdog</code> will be called periodically by our server while no requests are being issued (see option <code>--watchdog-ready-period</code> in options). If it fails, the server will try to kill and restart <code>MyApplication</code>. As an example we verify that we get an expected output from a known input:</li> </ul> <pre><code>    def watchdog(self) -&gt; int:\n        result = self.question_answerer(self.dummy_inputs_dict)\n        return RESULT_OK if result[\"answer\"] == \"Rob\" else RESULT_APPLICATION_ERROR\n</code></pre>"},{"location":"walkthrough/#write-ssf-config","title":"Write SSF config","text":"<p>The SSF config is the point of contact between our application and SSF. This will define all the metadata, the requirements (such as Python libraries needed for our application, the base Docker image to use, and so on), and also define our API.</p> <p>The SSF config folder can be considered the primary application folder or context. All files and modules should be specified relative to the SSF config folder. The current working directory will be set to the application module folder before SSF calls any of the application entry points (<code>build</code> or <code>request</code> etc.).</p> <p>Let's create <code>ssf_config.yaml</code> :</p> <pre><code># Copyright (c) 2023 Graphcore Ltd. All rights reserved.\nssf_version: 1.0.0\n\napplication:\n  id: qa_api\n  name: Question Answering API\n  desc: A very simple QA API\n  version: 1.0\n  module: my_app.py\n  ipus: 2\n  trace: True\n  artifacts: [exe_cache/**/*]\n  dependencies:\n    python: git+https://github.com/huggingface/optimum-graphcore.git@97c11c3\n\n  package:\n    inclusions: [exe_cache/**/*]\n    exclusions: []\n    docker:\n        baseimage: \"graphcore/pytorch:latest\"\n\nendpoints:\n\n  - id: QA\n    version: 1\n    desc: Question answering model\n    custom: ~\n\n    inputs:\n\n      - id: context\n        type: String\n        desc: Context\n        example: \"The large green ball bounced down the twisty road\"\n\n      - id: question\n        type: String\n        desc: Question\n        example: \"What colour is the ball?\"\n\n    outputs:\n\n      - id: answer\n        type: String\n        desc: Answer in the text\n\n      - id: score\n        type: Float\n        desc: Probability score\n</code></pre> <p>Now let's explain the main lines:</p> <ul> <li>Under <code>application</code>:  </li> </ul> <p><code>module</code> tells us where to find the interface that we have implemented:</p> <pre><code>module: my_app.py\n</code></pre> <p>Since we are using IPUs, let's check the resources used. The distillbert-base IPU config indicates 2 IPUs. With this config line, SSF will verify the system can acquire 2 IPUs when running the command <code>run</code> or <code>test</code>.</p> <pre><code>ipus: 2\n</code></pre> <p>Our model needs the <code>optimum-graphcore</code> package, we can specify any <code>pip</code> packages here (as a list or a requirements file path):</p> <pre><code>dependencies:\n    python: git+https://github.com/huggingface/optimum-graphcore.git\n</code></pre> <p>The <code>package</code> section refers to the gc-ssf package command, we can edit how we want SSF to build our container. We can include any files used by our application (and exclude some others), glob patterns are supported. Let's include everthing generated in the compilation cache.</p> <pre><code>    inclusions: [exe_cache/**/*]\n    exclusions: []\n</code></pre> <p>Finally we want to use Graphcore's base image with pre-installed PyTorch, so we can run <code>optimum-graphcore</code> without issue:</p> <pre><code>docker:\n        baseimage: \"graphcore/pytorch:latest\"\n</code></pre> <ul> <li>Under <code>endpoints</code>:  </li> </ul> <p>This is how SSF will generate our API.</p> <pre><code>id: QA\n    version: 1\n</code></pre> <p>This endpoint path will be <code>v1/QA</code>. Now let's remember our application <code>request(self, params: dict, meta: dict)</code> method. We want to describe here the <code>inputs</code> dictionaries using the names of the keys (<code>context</code>, <code>question</code>) and ssf types.</p> <pre><code>    inputs:\n      - id: context\n        type: String\n        desc: A context\n        example: \"The large green ball bounced down the twisty road\"\n\n      - id: question\n        type: String\n        desc: The question\n        example: \"What colour is the ball?\"\n</code></pre> <p>We also want to describe the <code>outputs</code>. Notice we are only selecting <code>answer</code> and <code>score</code> from our results as we are not interested in returning the <code>start</code> and <code>end</code> keys.</p> <pre><code>    outputs:\n\n      - id: answer\n        type: String\n        desc: Answer in the text\n\n      - id: score\n        type: Float\n        desc: Probability score\n</code></pre> <p>Our application is officially ready!  Now let's see what SSF can do.</p>"},{"location":"walkthrough/#use-ssf","title":"Use SSF","text":"<p>We should now have the following file structure:</p> <pre><code>project_directory/\n    - ssf_config.yaml\n    - my_app.py\n</code></pre>"},{"location":"walkthrough/#running-the-application-locally-for-development-and-testing","title":"Running the application locally for development and testing","text":"<p>We can use the SSF commands to run our application:</p> <pre><code>gc-ssf init build run --config ssf_config.yaml\n</code></pre> <p>The output should look similar to this:</p> <pre><code>demo@dev2:~/workspace/ssf$ gc-ssf init build run --config examples/walkthrough/ssf_config.yaml\n2023-10-19 12:55:14,483 420941     INFO      &gt; Config /nethome/demmo/workspace/ssf/examples/walkthrough/ssf_config.yaml (cli.py:639)\n2023-10-19 12:55:14,490 420941     INFO      application.license_name not specified. Defaulting to 'None' (load_config.py:375)\n...\n2023-10-19 12:56:22,004 420941     INFO      &gt; Lifespan start (server.py:82)\n2023-10-19 12:56:22,004 420941     INFO      Lifespan start : start application (threaded) (server.py:83)\n2023-10-19 12:56:22,005 420941     INFO      Application startup complete. (on.py:62)\n2023-10-19 12:56:22,006 420941     INFO      Uvicorn running on http://0.0.0.0:8100 (Press CTRL+C to quit) (server.py:219)\n...\n2023-10-19 12:56:44,676 420941     INFO      Dispatcher ready (dispatcher.py:542)\n2023-10-19 12:56:49,493 421639     INFO      [0] Dispatcher polling application replica watchdog (dispatcher.py:242)\n</code></pre> <p>We can see the address and port on which the application end-points have been started.  In this case localhost (0.0.0.0) and port 8100. We can also see when the dispatcher object through which calls (requests) to the application are made is ready. We will see repeated polls of the application watchdog while the end-point is idle; this is the SSF built-in watchdog feature. See watchdog for further details.</p> <p>Use a browser to open the endpoint docs with the format <code>http://&lt;address&gt;/docs</code>, for example <code>http://0.0.0.0:8100/docs</code>.  </p> <p>Use CTRL-C to stop the running application.  </p> <p>Tip: If you are using Visual Studio Code with a remote connection to your development host then you can use the Port forwarding feature to add the served port (<code>8100</code> in this example) and browse the endpoint directly in your VSC client using the built-in simple browser.</p>"},{"location":"walkthrough/#packaging-and-deployment","title":"Packaging and Deployment","text":"<p>Once we are satisfied the application is working correctly, we can package and deploy it.</p> <p>We can use the SSF commands for several different scenarios. First we should decide which commands we want to run locally (on our current machine) and which commands will run on the remote (deployment) machine.</p> <p>Let's look at a couple of examples.</p>"},{"location":"walkthrough/#example-1-deployment-using-an-application-specific-packaged-image","title":"Example 1 - deployment using an application-specific packaged image","text":"<p>In this first example we build our server locally and deploy its image via Docker Hub. The workflow can be summarised as follows:</p> <pre><code>(local)-&gt; init, build, package, publish, deploy\n(remote)-&gt; run\n</code></pre> <ul> <li>The <code>init</code> and <code>build</code> steps are run locally, to compile the model before packaging.</li> <li>The <code>package</code> step creates the container image locally, and <code>publish</code> pushes it to Docker Hub.</li> <li>Finally <code>deploy</code> sends and executes the deployment script on our deployment target. In the previous step, the container image was packaged in such a way to ensure it executes <code>run</code> when started on the remote machine.</li> </ul> <p>Let's build our container: We use <code>--package-tag</code> to replace the tag from the config with our Docker username since we will push the image to Docker hub.</p> <pre><code>gc-ssf init build package --config ssf_config.yaml --package-tag &lt;docker-username&gt;/&lt;repo-name&gt;\n</code></pre> <p>The output should look similar to this:</p> <pre><code>demo@dev2:~/workspace/ssf$ gc-ssf init build package --config examples/walkthrough/ssf_config.yaml --package-tag graphcore/cloudsolutions-dev:walkthrough_api\n2023-10-19 10:11:17,670 380504     INFO      &gt; Config /nethome/demo/workspace/ssf/examples/walkthrough/ssf_config.yaml (cli.py:639)\n2023-10-19 10:11:17,675 380504     INFO      application.license_name not specified. Defaulting to 'None' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.license_url not specified. Defaulting to 'None' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.terms_of_service not specified. Defaulting to 'None' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.startup_timeout not specified. Defaulting to '300' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.package.name not specified. Defaulting to 'qa_api.1.0.tar.gz' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.package.tag not specified. Defaulting to 'qa_api:1.0' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.package.docker.run not specified. Defaulting to '' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.max_batch_size not specified. Defaulting to '1' (load_config.py:375)\n2023-10-19 10:11:17,675 380504     INFO      application.syspaths not specified. Defaulting to '[]' (load_config.py:375)\n2023-10-19 10:11:17,676 380504     INFO      endpoints.0.http_param_format not specified. Defaulting to 'None' (load_config.py:375)\n2023-10-19 10:11:17,676 380504     INFO      endpoints.0.outputs.0.example not specified. Defaulting to 'None' (load_config.py:375)\n2023-10-19 10:11:17,676 380504     INFO      endpoints.0.outputs.1.example not specified. Defaulting to 'None' (load_config.py:375)\n2023-10-19 10:11:17,676 380504     INFO      Adding syspath /nethome/demo/workspace/ssf/examples/walkthrough (cli.py:683)\n2023-10-19 10:11:17,676 380504     INFO      &gt; ==== Init ==== (init.py:17)\n2023-10-19 10:11:17,676 380504     INFO      &gt; Cleaning endpoints (init.py:19)\n2023-10-19 10:11:17,677 380504     INFO      &gt; Cleaning application (init.py:22)\n2023-10-19 10:11:17,678 380504     INFO      Clean /nethome/demo/workspace/ssf/examples/walkthrough/exe_cache/8218824126841776145.popef (init.py:36)\n2023-10-19 10:11:17,679 380504     INFO      &gt; ==== Build ==== (build.py:19)\n2023-10-19 10:11:17,679 380504     INFO      &gt; Generate_endpoints (build.py:26)\n2023-10-19 10:11:17,679 380504     INFO      loading module /nethome/demo/workspace/ssf/ssf/generate_endpoints_fastapi.py with module name generate_endpoints (utils.py:298)\n2023-10-19 10:11:17,684 380504     INFO      &gt; Load application (build.py:29)\n2023-10-19 10:11:17,684 380504     INFO      Creating application main interface (application.py:160)\n2023-10-19 10:11:17,684 380504     INFO      Checking application dependencies (application.py:161)\n2023-10-19 10:11:17,684 380504     INFO      installing python packages git+https://github.com/huggingface/optimum-graphcore.git@97c11c3 (utils.py:276)\n2023-10-19 10:11:26,230 380504     INFO      Loading qa_api application main interface from /nethome/demo/workspace/ssf/examples/walkthrough/my_app.py with module id qa_api (application.py:168)\n2023-10-19 10:11:26,230 380504     INFO      loading module /nethome/demo/workspace/ssf/examples/walkthrough/my_app.py with module name qa_api (utils.py:298)\n2023-10-19 10:11:27,765 380504     INFO      Created a temporary directory at /tmp/tmpu3ter_oa (instantiator.py:21)\n2023-10-19 10:11:27,766 380504     INFO      Writing /tmp/tmpu3ter_oa/_remote_module_non_scriptable.py (instantiator.py:76)\n2023-10-19 10:11:28,553 380504     INFO      &lt;module 'qa_api' from '/nethome/demo/workspace/ssf/examples/walkthrough/my_app.py'&gt; (application.py:172)\n2023-10-19 10:11:28,553 380504     INFO      Found &lt;class 'qa_api.MyApplication'&gt;, MyApplication (application.py:225)\n2023-10-19 10:11:28,553 380504     INFO      instance=&lt;qa_api.MyApplication object at 0x7f6c3ba5d3a0&gt; (build.py:32)\n2023-10-19 10:11:28,553 380504     INFO      &gt; Build application (build.py:34)\n2023-10-19 10:11:28,626 380504     INFO      Compiling model... (my_app.py:26)\nNo padding arguments specified, so padding to 384 by default. Inputs longer than 384 will be truncated.\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:36&lt;00:00]\n2023-10-19 10:12:15,724 380504     INFO      &gt; ==== Package ==== (package.py:51)\n2023-10-19 10:12:15,724 380504     INFO      &gt; Packaging qa_api to /nethome/demo/workspace/ssf/.package/qa_api (package.py:71)\n2023-10-19 10:12:15,725 380504     INFO      &gt; Package name qa_api.1.0.tar.gz (package.py:72)\n2023-10-19 10:12:15,725 380504     INFO      &gt; Package tag graphcore/cloudsolutions-dev:walkthrough_api (package.py:73)\n2023-10-19 10:12:15,806 380504     INFO      &gt; Package SSF from /nethome/demo/workspace/ssf/ssf (package.py:111)\n2023-10-19 10:12:15,862 380504     INFO      &gt; Package Application from /nethome/demo/workspace/ssf/examples/walkthrough (package.py:169)\n2023-10-19 10:12:15,960 380504     INFO      &gt; Package Endpoint files (package.py:185)\n2023-10-19 10:12:15,962 380504     INFO      &gt; Gathering pip requirements (package.py:206)\n2023-10-19 10:12:15,963 380504     INFO      &gt; Generate container image (package.py:245)\n2023-10-19 10:12:15,963 380504     INFO      application.package.docker_run not specified. Defaulting to '' (utils.py:67)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Package: (package.py:280)\n2023-10-19 10:14:31,414 380504     INFO      &gt; qa_api.1.0.tar.gz (from /nethome/demo/workspace/ssf/.package/qa_api/src) (package.py:281)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Test run: 'cd /nethome/demo/workspace/ssf/.package/qa_api/src &amp;&amp; ./run.sh' (package.py:282)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Docker: (package.py:284)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Run: 'docker run --rm -d --network host --name qa_api graphcore/cloudsolutions-dev:walkthrough_api' (package.py:285)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Run with IPU devices: 'gc-docker -- --rm -d  --name qa_api graphcore/cloudsolutions-dev:walkthrough_api' (package.py:288)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Logs: 'docker logs -f qa_api' (package.py:292)\n2023-10-19 10:14:31,414 380504     INFO      &gt; Stop: 'docker stop qa_api' (package.py:293)\n2023-10-19 10:14:31,414 380504     INFO      Exit with 0 (cli.py:739)\n</code></pre> <p>We should be able to see that a new <code>.package/</code> directory has been created, it contains the packaged application with name <code>qa_api</code>. This is the packaged source used to build the docker image. We can test or debug the packaged application source locally by moving to the <code>.package/qa_api/src</code> directory and running <code>./run.sh</code>. This is the same entry-point that will be used when the application docker image is deployed remotely.</p> <p>We can also verify that our application image was created during the package step with docker, for example:</p> <pre><code>demo@dev2:~/workspace/ssf$ docker images\nREPOSITORY                     TAG                           IMAGE ID       CREATED          SIZE\ngraphcore/cloudsolutions-dev   walkthrough_api               9e301f5fb62f   7 minutes ago    3.57GB\n</code></pre> <p>For the next step, a login to a Docker Hub registry is necessary. SSF will log in temporarily to Docker when using <code>--docker-username</code> and <code>--docker-password</code> options. But if you are already logged in with the correct account, you don't need these options for this step.</p> <p>We can now publish our image on Docker hub.  </p> <p>Let's specify that we will push it with the same tag as during the package step using <code>--package-tag</code></p> <pre><code>gc-ssf publish --config ssf_config.yaml --package-tag &lt;docker-username&gt;/&lt;repo-name&gt; --docker-username &lt;docker-username&gt; --docker-password &lt;token&gt;\n</code></pre> <p>Finally, we can deploy the container to Gcore.  </p> <p>We will assume that we have already set up a VM with at least 2 IPUs with the IP address 123.456.789.0 and the default username \"ubuntu\". To access it, we have a private key. SSF will need this to access the VM and deploy. To pass the key securely we will store it in an <code>env</code> variable and use the option <code>--add-ssh-key</code>. For instance we can set it from a file:</p> <pre><code>SSH_KEY=$(cat ssh_key_file)  gc-ssf --add-ssh-key SSH_KEY\n</code></pre> <p>Now let's run the <code>deploy</code> command with the following set of options. We also pass our Docker token via the option <code>--docker-password</code> which is needed to pull the image from our Docker hub repo to the remote VM (but this is not needed if you use a public repo).</p> <pre><code>gc-ssf deploy --config ssf_config.yaml --deploy-platform Gcore --port 8100 --deploy-gcore-target-address 123.456.789.0 --deploy-gcore-target-username ubuntu --docker-username &lt;docker-username&gt; --docker-password &lt;token&gt; --package-tag &lt;username&gt;/&lt;repo-name&gt;:latest --deploy-package\n</code></pre> <ul> <li> <p>Notice the use of <code>--deploy-package</code> to specify that we want to deploy the application-specific package that we published previously.</p> </li> <li> <p>You can combine the <code>--add-ssh-key</code> argument with other SSF commands, so we might choose to include it with <code>gc-ssf deploy</code> and use a single invocation of SSF to configure keys and deploy the packaged application image.</p> </li> </ul> <p>With this configuration our API endpoint should be available at <code>http://123.456.789.0:8100/v1/QA.</code></p> <p>Since it's using FastAPI you can also test it with Swagger UI under the path <code>http://123.456.789.0:8100/docs</code>.</p> <p>Under the hood, the <code>deploy</code> command will simply run a script on the Gcore VM to pull our custom image from Docker Hub and run it.</p> <p>It is valid to run <code>gc-ssf ... init build package publish</code> on a machine that supports the target (for example, has the required IPU and Poplar SDK for the <code>build</code>) and then later deploy the published application from any client with <code>gc-ssf ... deploy</code>. In which case the client from which <code>deploy</code> is issued doesn't strictly need IPUs or the Poplar SDK.</p> <p>The following diagram summarises the operations of this first example. </p>"},{"location":"walkthrough/#example-2-deployment-using-the-generic-ssf-image","title":"Example 2 - deployment using the generic SSF image","text":"<p>Sometimes our local environment doesn't allow us to build containers, or we just want to experiment quickly. In this second example we won't build an application-specific container image. This means that the following workflow is possible:</p> <pre><code>(local)-&gt; deploy\n(remote)-&gt; init, build, run\n</code></pre> <p>This is made possible by storing our model in a repository and using a pre-built SSF image. First we need to set up a remote repository for our model. For example, using a GitHub account we could do:</p> <pre><code>  cd project_directory &amp;&amp; git init\n  git add -A\n  git commit -m 'First commit'\n  git remote add origin git@github.com:your-username/project_directory.git\n  git push -u -f origin main\n</code></pre> <p>To register the VM SSH key locally we could do:</p> <pre><code>SSH_KEY=$(cat ssh_key_file)  gc-ssf --add-ssh-key SSH_KEY\n</code></pre> <p>If you use a private repo, you will also need to allow your VM to clone from it. To do that you will need to generate a GitHub deploy-key for your repo (or an equivalent access-limited SSH key). Then, pass it with the <code>deploy</code> command using an env variable (for example <code>MY_DEPLOY_KEY</code>) and <code>--add-ssh-key</code>.</p> <p>Now let's use <code>deploy</code> targeting our git repo:</p> <pre><code>MY_DEPLOY_KEY=$(cat github_deploy_key) gc-ssf deploy --config 'git@github.com:your-username/project_directory.git|ssf_config.yaml' --port 8100  --deploy-platform Gcore --deploy-gcore-target-address 123.456.789.0 --deploy-gcore-target-username ubuntu --add-ssh-key MY_DEPLOY_KEY\n</code></pre> <ul> <li>Notice this time we are not using <code>--deploy-package</code>, so SSF will deploy the default public generic SSF image. <code>gc-ssf --help</code> can be used to see the default SSF image used for deployment.</li> </ul> <p>Under the hood the <code>deploy</code> command will send and run a script on the Gcore VM. That will pull the public SSF image from Docker Hub, build and run it. The container entry point will clone our repo and issue the three commands <code>init build run</code>.</p> <p>As in the first example, our API endpoint should be available at <code>http://123.456.789.0:8100/v1/QA</code>. You can also test it with Swagger UI under the path <code>http://123.456.789.0:8100/docs</code>.</p> <p>The following diagram summarises the operations of this second example. </p> <p>Note that we only deployed a Docker container on a Gcore VM. You can still SSH normally into your VM and use the usual Docker commands, for example <code>docker container ls</code>, <code>docker log...</code>, <code>docker stop ...</code>.</p> <p>NOTE: This feature defaults to using the generic Graphcore published SSF image corresponding to your local version of SSF (<code>gc-ssf</code>). If this is not available for your current version of SSF then you can still use the feature by creating your own generic SSF image:</p> <ul> <li>Build the generic SSF image for your local version with <code>gc-ssf package --package-tag ssf</code> (this will package SSF without binding an application)</li> <li>Publish the resulting SSF image to your own Docker repository</li> <li>When deploying, add <code>--package-tag &lt;published ssf image&gt;</code> to deploy your published SSF image instead of the default SSF image</li> </ul> <p>See building an SSF image</p>"},{"location":"walkthrough/#discussion-example-1-vs-example-2","title":"Discussion: Example 1 vs Example 2","text":"<p>These examples have shown two different ways to deploy on the Gcore platform with SSF. Both are serving your application with the same API, but it's important to underline their differences.</p>"},{"location":"walkthrough/#example-1-deployment-using-an-application-specific-packaged-image_1","title":"Example 1 - deployment using an application-specific packaged image","text":"<p>This gives you more control:  </p> <p>By packaging your app in advance with SSF, you create your own custom Docker image. Then you can version your images via Docker hub. This method can also have runtime advantages. By building and packaging some runtime-generated files in advance (such as IPUs pre-compiled executables) you can save some precious server startup time.</p>"},{"location":"walkthrough/#example-2-deployment-using-the-generic-ssf-image_1","title":"Example 2 - deployment using the generic SSF image","text":"<p>This is quicker but can have some runtime impact:  </p> <p>By deploying your model with the generic SSF image, you don't need to run Docker locally or worry about the packaging step, and your model can be versioned via git. The server startup time might be impacted since the application <code>build</code> step will be triggered in the deployment environment before the server startup.  Of course, you can still include cached files as part of the model repository. But depending on the size of the files you might prefer to package your app in advance and follow Example 1, for instance if you have a very large model to compile.</p>"}]}